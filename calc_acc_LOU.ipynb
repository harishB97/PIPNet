{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bf3473e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "import sys, os\n",
    "import random\n",
    "import numpy as np\n",
    "from shutil import copy\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "\n",
    "from omegaconf import OmegaConf\n",
    "import shutil\n",
    "import pickle\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "\n",
    "from torchvision.datasets.folder import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "# from skimage.filters import threshold_local, gaussian\n",
    "\n",
    "from datetime import datetime\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ecb88ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runs/205-LOUSet4-PruningBF=1.1NaiveHPIPNetMaskL1=0.5MaskTrainExtra=05epsEps=60Cl=2.0TanhDesc=0.05MinCont=0.1_cnext26_CUB-190-imgnet-224_WeightedCE_with-equalize-aug_img=224_nprotos=10pc\n"
     ]
    }
   ],
   "source": [
    "# 154 pruning CUB-18\n",
    "# run_path = \"runs/154-PruningNaiveHPIPNet_cnext13_CUB-18-imgnet-224_with-equalize-aug_img=224_nprotos=20\"\n",
    "\n",
    "# 155 pruning CUB-190\n",
    "# run_path = \"runs/155-PruningNaiveHPIPNet_cnext13_CUB-190-imgnet-224_with-equalize-aug_img=224_nprotos=20\"\n",
    "\n",
    "# 153 pruning CUB-29\n",
    "# run_path = \"runs/153-PruningNaiveHPIPNet_cnext13_CUB-29-imgnet-224_with-equalize-aug_img=224_nprotos=20\"\n",
    "\n",
    "# 156 pruning CUB-18 LOU3\n",
    "# run_path = \"runs/156-PruningNaiveHPIPNet_LOU3_cnext13_CUB-18-imgnet-224_with-equalize-aug_img=224_nprotos=20\"\n",
    "\n",
    "# 157 pruning CUB-29 LOU3\n",
    "# run_path = \"runs/157-PruningNaiveHPIPNet_LOU3_cnext13_CUB-29-imgnet-224_with-equalize-aug_img=224_nprotos=20\"\n",
    "\n",
    "# run_path = \"runs/178-PruningNaiveHPIPNetMaskL1=0.5MaskTrainExtra=15epsEps=60TanhDesc=0.05MinCont=0.1_cnext26_CUB-190-imgnet-224_WeightedCE_with-equalize-aug_img=224_nprotos=20\"\n",
    "# ckpt_file_name = 'net_trained_last'\n",
    "\n",
    "# run_path = \"runs/179-PruningNaiveHPIPNetMaskL1=0.5MaskTrainExtra=15epsEps=60TanhDesc=0.05MinCont=0.1_cnext26_CUB-190-224_WeightedCE_with-equalize-aug_img=224_nprotos=20\"\n",
    "\n",
    "# run_path = \"runs/180-PruningNaiveHPIPNetMaskL1=0.5MaskTrainExtra=15epsEps=60TanhDesc=2.0MinCont=0.1_cnext26_CUB-190-imgnet-224_WeightedCE_with-equalize-aug_img=224_nprotos=20\"\n",
    "\n",
    "# run_path = \"runs/181-PruningNaiveHPIPNetMaskL1=0.5MaskTrainExtra=15epsEps=60TanhDesc=2.0MinCont=0.1_cnext26_CUB-190-224_WeightedCE_with-equalize-aug_img=224_nprotos=20\"\n",
    "\n",
    "# run_path = \"runs/182-PruningNaiveHPIPNetMaskL1=0.5MaskTrainExtra=15epsEps=60TanhDesc=0.1MinCont=0.1_cnext26_CUB-190-imgnet-224_WeightedCE_with-equalize-aug_img=224_nprotos=20\"\n",
    "\n",
    "# run_path = \"runs/183-PruningBF=1.1NaiveHPIPNetMaskL1=0.5MaskTrainExtra=15epsEps=60TanhDesc=0.05MinCont=0.1_cnext26_CUB-190-imgnet-224_WeightedCE_with-equalize-aug_img=224_nprotos=20\"\n",
    "\n",
    "# run_path = \"runs/185-LOUSet1-PruningBF=1.1NaiveHPIPNetMaskL1=0.5MaskTrainExtra=15epsEps=60TanhDesc=0.05MinCont=0.1_cnext26_CUB-190-imgnet-224_WeightedCE_with-equalize-aug_img=224_nprotos=20\"\n",
    "\n",
    "# run_path = \"runs/191-LOUSet2-PruningBF=1.1NaiveHPIPNetMaskL1=0.5MaskTrainExtra=05epsEps=85Cl=4.0TanhDesc=0.05MinCont=0.5_cnext26_CUB-190-imgnet-224_WeightedCE_with-equalize-aug_img=224_nprotos=20\"\n",
    "\n",
    "# run_path = \"runs/192-PruningNaiveHPIPNetMaskL1=0.5MaskTrainExtra=05epsEps=85Cl=4.0NoTanhDescMinCont=0.5_cnext26_CUB-190-imgnet-224_WeightedCE_with-equalize-aug_img=224_nprotos=20\"\n",
    "\n",
    "# run_path = \"runs/193-LOUSet3-PruningBF=1.1NaiveHPIPNetMaskL1=0.5MaskTrainExtra=05epsEps=85Cl=4.0TanhDesc=0.05MinCont=0.5_cnext26_CUB-190-imgnet-224_WeightedCE_with-equalize-aug_img=224_nprotos=20\"\n",
    "# ckpt_file_name = 'net_trained_last'\n",
    "\n",
    "# run_path = \"runs/195-LOUSet3-PruningBF=1.1NaiveHPIPNetMaskL1=0.5MaskTrainExtra=05epsEps=85Cl=4.0TanhDesc=0.05MinCont=0.5_cnext26_CUB-190-imgnet-224_WeightedCE_with-equalize-aug_img=224_nprotos=10pcOr1pd\"\n",
    "# ckpt_file_name = 'net_trained_last'\n",
    "\n",
    "# run_path = \"runs/198-rerun-LOUSet1-PruningBF=1.1NaiveHPIPNetMaskL1=0.5MaskTrainExtra=05epsEps=85Cl=4.0TanhDesc=0.05MinCont=0.5_cnext26_CUB-190-imgnet-224_WeightedCE_with-equalize-aug_img=224_nprotos=10pcOr1pd\"\n",
    "# ckpt_file_name = 'net_trained_last'\n",
    "\n",
    "# run_path = \"runs/199-rerun-LOUSet3-PruningBF=1.1NaiveHPIPNetOODEnt=-0.2MaskL1=0.5MaskTrainExtra=05epsEps=85Cl=4.0TanhDesc=0.05MinCont=0.5_cnext26_CUB-190-imgnet-224_WeightedCE_with-equalize-aug_img=224_nprotos=10pc\"\n",
    "# ckpt_file_name = 'net_trained_90'\n",
    "\n",
    "# run_path = \"runs/197-LOUSet3-PruningBF=1.1NaiveHPIPNetOODEnt=-0.2MaskL1=0.5MaskTrainExtra=05epsEps=85Cl=4.0TanhDesc=0.05MinCont=0.5_cnext26_CUB-190-imgnet-224_WeightedCE_with-equalize-aug_img=224_nprotos=10pcOr1pd\"\n",
    "# ckpt_file_name = 'net_trained_90'\n",
    "\n",
    "# run_path = \"runs/200-rerun-LOUSet1-PruningBF=1.1NaiveHPIPNetOODEnt=-0.2MaskL1=0.5MaskTrainExtra=05epsEps=85Cl=4.0TanhDesc=0.05MinCont=0.5_cnext26_CUB-190-imgnet-224_WeightedCE_with-equalize-aug_img=224_nprotos=10pc\"\n",
    "# ckpt_file_name = 'net_trained_last'\n",
    "\n",
    "# run_path = \"runs/201-LOUSet1-PruningBF=1.1NaiveHPIPNetOODEnt=-0.2MaskL1=0.5MaskTrainExtra=05epsEps=85Cl=4.0TanhDesc=0.05MinCont=0.5_cnext26_CUB-190-imgnet-224_WeightedCE_with-equalize-aug_img=224_nprotos=10pcOr1pd\"\n",
    "# ckpt_file_name = 'net_trained_90'\n",
    "\n",
    "run_path = \"runs/205-LOUSet4-PruningBF=1.1NaiveHPIPNetMaskL1=0.5MaskTrainExtra=05epsEps=60Cl=2.0TanhDesc=0.05MinCont=0.1_cnext26_CUB-190-imgnet-224_WeightedCE_with-equalize-aug_img=224_nprotos=10pc\"\n",
    "ckpt_file_name = 'net_trained_last'\n",
    "\n",
    "# run_path = \"runs/206-LOUSet5-PruningBF=1.1NaiveHPIPNetMaskL1=0.5MaskTrainExtra=05epsEps=60Cl=2.0TanhDesc=0.05MinCont=0.1_cnext26_CUB-190-imgnet-224_WeightedCE_with-equalize-aug_img=224_nprotos=10pc\"\n",
    "# ckpt_file_name = 'net_trained_last'\n",
    "\n",
    "# run_path = \"runs/207-PruningBF=1.1NaiveHPIPNetMaskL1=0.5MaskTrainExtra=05epsEps=60Cl=2.0TanhDesc=0.05MinCont=0.1_cnext26_BUT-51-224_WeightedCE_with-equalize-aug_img=224_nprotos=10pc\"\n",
    "# ckpt_file_name = 'net_trained_last'\n",
    "\n",
    "# run_path = \"runs/208-PruningBF=1.1NaiveHPIPNetMaskL1=0.5MaskTrainExtra=05epsEps=60Cl=2.0TanhDesc=0.05MinCont=0.1_cnext26_FISH-38-224_WeightedCE_with-equalize-aug_img=224_nprotos=10pc\"\n",
    "# ckpt_file_name = 'net_trained_last'\n",
    "\n",
    "\n",
    "# try:\n",
    "#     sys.path.remove('/home/harishbabu/projects/PIPNet')\n",
    "# except:\n",
    "#     pass\n",
    "# sys.path.insert(0, os.path.join(run_path, 'source_clone'))\n",
    "\n",
    "print(run_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d53cfe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Heatmaps showing where a prototype is found will not be generated because OpenCV is not installed.\n"
     ]
    }
   ],
   "source": [
    "from pipnet.pipnet import PIPNet, get_network\n",
    "from util.log import Log\n",
    "from util.args import get_args, save_args, get_optimizer_nn\n",
    "from util.data import get_dataloaders\n",
    "from util.func import init_weights_xavier\n",
    "from pipnet.train import train_pipnet, test_pipnet\n",
    "# from pipnet.test import eval_pipnet, get_thresholds, eval_ood\n",
    "from util.eval_cub_csv import eval_prototypes_cub_parts_csv, get_topk_cub, get_proto_patches_cub\n",
    "from util.vis_pipnet import visualize, visualize_topk\n",
    "from util.visualize_prediction import vis_pred, vis_pred_experiments\n",
    "from util.node import Node\n",
    "from util.phylo_utils import construct_phylo_tree, construct_discretized_phylo_tree\n",
    "from util.func import get_patch_size\n",
    "from util.data import ModifiedLabelLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e5271b-b798-43a6-86b2-8aef7c52a7ff",
   "metadata": {},
   "source": [
    "# Save leave_out_classes to a variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5f0fbbc-f837-48cf-a5e2-3cc4a4be71ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "args_file = open(os.path.join(run_path, 'metadata', 'args.pickle'), 'rb')\n",
    "args = pickle.load(args_file)\n",
    "\n",
    "if ('leave_out_classes' in args) and (args.leave_out_classes != ''):\n",
    "        with open(args.leave_out_classes, 'r') as file:\n",
    "            leave_out_classes = [line.strip() for line in file]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e5a1043-540f-448c-b94c-ee06ba6bd91f",
   "metadata": {},
   "source": [
    "# Define tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c11d438b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------- No discretization -------------------------\n"
     ]
    }
   ],
   "source": [
    "args_file = open(os.path.join(run_path, 'metadata', 'args.pickle'), 'rb')\n",
    "args = pickle.load(args_file)\n",
    "\n",
    "if args.phylo_config:\n",
    "    phylo_config = OmegaConf.load(args.phylo_config)\n",
    "\n",
    "if args.phylo_config:\n",
    "    # construct the phylo tree\n",
    "    if phylo_config.phyloDistances_string == 'None':\n",
    "        if '031' in run_path: # this run uses a different phylogeny file that had an extra root node which is a mistake\n",
    "            root = construct_phylo_tree('/home/harishbabu/data/phlyogenyCUB/18Species-with-extra-root-node/1_tree-consensus-Hacket-18Species-modified_cub-names_v1.phy')\n",
    "        else:\n",
    "            root = construct_phylo_tree(phylo_config.phylogeny_path)\n",
    "        print('-'*25 + ' No discretization ' + '-'*25)\n",
    "    else:\n",
    "        root = construct_discretized_phylo_tree(phylo_config.phylogeny_path, phylo_config.phyloDistances_string)\n",
    "        print('-'*25 + ' Discretized ' + '-'*25)\n",
    "else:\n",
    "    # construct the tree (original hierarchy as described in the paper)\n",
    "    root = Node(\"root\")\n",
    "    root.add_children(['animal','vehicle','everyday_object','weapon','scuba_diver'])\n",
    "    root.add_children_to('animal',['non_primate','primate'])\n",
    "    root.add_children_to('non_primate',['African_elephant','giant_panda','lion'])\n",
    "    root.add_children_to('primate',['capuchin','gibbon','orangutan'])\n",
    "    root.add_children_to('vehicle',['ambulance','pickup','sports_car'])\n",
    "    root.add_children_to('everyday_object',['laptop','sandal','wine_bottle'])\n",
    "    root.add_children_to('weapon',['assault_rifle','rifle'])\n",
    "    # flat root\n",
    "    # root.add_children(['scuba_diver','African_elephant','giant_panda','lion','capuchin','gibbon','orangutan','ambulance','pickup','sports_car','laptop','sandal','wine_bottle','assault_rifle','rifle'])\n",
    "root.assign_all_descendents()\n",
    "\n",
    "exp_no = int(os.path.basename(run_path)[:3])\n",
    "\n",
    "if exp_no < 77:\n",
    "    if ('num_protos_per_descendant' in args) and (args.num_protos_per_descendant > 0):\n",
    "        for node in root.nodes_with_children():\n",
    "            node.set_num_protos(args.num_protos_per_descendant)\n",
    "if exp_no == 77:\n",
    "    # update num of protos per node based on num_protos_per_descendant\n",
    "    if args.num_features == 0 and args.num_protos_per_descendant == 0:\n",
    "        raise Exception('Either of num_features or num_protos_per_descendant must be greater than zero')\n",
    "    for node in root.nodes_with_children():\n",
    "        node.set_num_protos(num_protos_per_descendant=args.num_protos_per_descendant,\\\n",
    "                                                            min_protos=args.num_features)\n",
    "\n",
    "elif 'num_protos_per_child' in args:\n",
    "    if ('num_protos_per_descendant' in args):\n",
    "        # update num of protos per node based on num_protos_per_descendant\n",
    "        if args.num_features == 0 and args.num_protos_per_descendant == 0 and args.num_protos_per_child == 0:\n",
    "            raise Exception('Either of num_features or num_protos_per_descendant must be greater than zero')\n",
    "        for node in root.nodes_with_children():\n",
    "            node.set_num_protos(num_protos_per_descendant=args.num_protos_per_descendant,\\\n",
    "                                num_protos_per_child=args.num_protos_per_child,\\\n",
    "                                min_protos=args.num_features,\\\n",
    "                                split_protos=('protopool' in args) and (args.protopool == 'n'))\n",
    "else:\n",
    "    if ('num_protos_per_descendant' in args):\n",
    "        # update num of protos per node based on num_protos_per_descendant\n",
    "        if args.num_features == 0 and args.num_protos_per_descendant == 0:\n",
    "            raise Exception('Either of num_features or num_protos_per_descendant must be greater than zero')\n",
    "        for node in root.nodes_with_children():\n",
    "            node.set_num_protos(num_protos_per_descendant=args.num_protos_per_descendant,\\\n",
    "                                num_protos_per_child=0,\\\n",
    "                                min_protos=args.num_features,\\\n",
    "                                split_protos=('protopool' in args) and (args.protopool == 'n'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "751cc10c-e33b-472c-b904-36e94ab2c189",
   "metadata": {},
   "source": [
    "# Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e3ed910",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num classes (k) =  190 ['cub_001_Black_footed_Albatross', 'cub_002_Laysan_Albatross', 'cub_003_Sooty_Albatross', 'cub_004_Groove_billed_Ani', 'cub_005_Crested_Auklet'] etc.\n",
      "228 228\n",
      "Number of prototypes:  768\n",
      "----------Prototypes per descendant: 0----------\n",
      "Assigned 20 protos to node root\n",
      "Assigned 30 protos to node 129+024+067\n",
      "Assigned 20 protos to node 089+046\n",
      "Assigned 20 protos to node 129+065\n",
      "Assigned 20 protos to node 024+051\n",
      "Assigned 20 protos to node 067+070\n",
      "Assigned 20 protos to node 089+090\n",
      "Assigned 20 protos to node 046+087\n",
      "Assigned 20 protos to node 129+192\n",
      "Assigned 20 protos to node 065+006\n",
      "Assigned 20 protos to node 024+031\n",
      "Assigned 20 protos to node 051+052\n",
      "Assigned 20 protos to node 067+068\n",
      "Assigned 20 protos to node 129+043\n",
      "Assigned 20 protos to node 192+081\n",
      "Assigned 20 protos to node 065+144\n",
      "Assigned 20 protos to node 006+071\n",
      "Assigned 20 protos to node 024+086\n",
      "Assigned 20 protos to node 031+004\n",
      "Assigned 20 protos to node 051+053\n",
      "Assigned 20 protos to node 067+069\n",
      "Assigned 20 protos to node 129+018\n",
      "Assigned 20 protos to node 043+078\n",
      "Assigned 20 protos to node 192+036\n",
      "Assigned 20 protos to node 081+083\n",
      "Assigned 20 protos to node 065+084\n",
      "Assigned 20 protos to node 144+147\n",
      "Assigned 20 protos to node 006+058\n",
      "Assigned 20 protos to node 071+072\n",
      "Assigned 20 protos to node 024+001\n",
      "Assigned 20 protos to node 031+032\n",
      "Assigned 20 protos to node 051+050\n",
      "Assigned 20 protos to node 129+107\n",
      "Assigned 20 protos to node 043+042\n",
      "Assigned 20 protos to node 078+038\n",
      "Assigned 20 protos to node 192+191\n",
      "Assigned 20 protos to node 036+188\n",
      "Assigned 20 protos to node 081+082\n",
      "Assigned 20 protos to node 065+061\n",
      "Assigned 20 protos to node 084+063\n",
      "Assigned 20 protos to node 144+143\n",
      "Assigned 20 protos to node 006+008\n",
      "Assigned 20 protos to node 024+100\n",
      "Assigned 20 protos to node 001+045\n",
      "Assigned 20 protos to node 031+033\n",
      "Assigned 20 protos to node 129+136\n",
      "Assigned 20 protos to node 107+151\n",
      "Assigned 20 protos to node 043+040\n",
      "Assigned 20 protos to node 078+041\n",
      "Assigned 20 protos to node 192+187\n",
      "Assigned 20 protos to node 191+189\n",
      "Assigned 20 protos to node 081+080\n",
      "Assigned 20 protos to node 082+079\n",
      "Assigned 20 protos to node 065+066\n",
      "Assigned 20 protos to node 061+064\n",
      "Assigned 20 protos to node 144+142\n",
      "Assigned 20 protos to node 006+005\n",
      "Assigned 20 protos to node 008+106\n",
      "Assigned 20 protos to node 024+023\n",
      "Assigned 20 protos to node 100+101\n",
      "Assigned 20 protos to node 001+003\n",
      "Assigned 20 protos to node 129+199\n",
      "Assigned 20 protos to node 136+085\n",
      "Assigned 20 protos to node 107+111\n",
      "Assigned 20 protos to node 151+153\n",
      "Assigned 20 protos to node 043+037\n",
      "Assigned 20 protos to node 040+102\n",
      "Assigned 20 protos to node 078+077\n",
      "Assigned 20 protos to node 192+190\n",
      "Assigned 20 protos to node 065+062\n",
      "Assigned 20 protos to node 144+145\n",
      "Assigned 20 protos to node 006+007\n",
      "Assigned 20 protos to node 024+025\n",
      "Assigned 20 protos to node 001+002\n",
      "Assigned 20 protos to node 129+118\n",
      "Assigned 20 protos to node 199+186\n",
      "Assigned 20 protos to node 136+138\n",
      "Assigned 20 protos to node 107+073\n",
      "Assigned 20 protos to node 111+112\n",
      "Assigned 20 protos to node 151+157\n",
      "Assigned 20 protos to node 153+154\n",
      "Assigned 20 protos to node 043+039\n",
      "Assigned 20 protos to node 065+059\n",
      "Assigned 20 protos to node 144+146\n",
      "Assigned 20 protos to node 129+104\n",
      "Assigned 20 protos to node 199+150\n",
      "Assigned 20 protos to node 186+185\n",
      "Assigned 20 protos to node 136+137\n",
      "Assigned 20 protos to node 107+093\n",
      "Assigned 20 protos to node 073+074\n",
      "Assigned 20 protos to node 151+156\n",
      "Assigned 20 protos to node 157+152\n",
      "Assigned 20 protos to node 153+155\n",
      "Assigned 20 protos to node 065+060\n",
      "Assigned 20 protos to node 144+141\n",
      "Assigned 20 protos to node 129+035\n",
      "Assigned 20 protos to node 199+094\n",
      "Assigned 20 protos to node 150+019\n",
      "Assigned 20 protos to node 107+030\n",
      "Assigned 20 protos to node 129+054\n",
      "Assigned 20 protos to node 035+055\n",
      "Assigned 20 protos to node 199+028\n",
      "Assigned 20 protos to node 150+149\n",
      "Assigned 20 protos to node 107+029\n",
      "Assigned 20 protos to node 129+175\n",
      "Assigned 20 protos to node 054+140\n",
      "Assigned 20 protos to node 035+048\n",
      "Assigned 20 protos to node 199+198\n",
      "Assigned 20 protos to node 150+091\n",
      "Assigned 20 protos to node 107+108\n",
      "Assigned 20 protos to node 129+011\n",
      "Assigned 20 protos to node 175+020\n",
      "Assigned 20 protos to node 054+057\n",
      "Assigned 20 protos to node 140+017\n",
      "Assigned 20 protos to node 035+056\n",
      "Assigned 20 protos to node 048+047\n",
      "Assigned 20 protos to node 199+194\n",
      "Assigned 20 protos to node 129+121\n",
      "Assigned 20 protos to node 011+013\n",
      "Assigned 20 protos to node 175+099\n",
      "Assigned 20 protos to node 054+014\n",
      "Assigned 20 protos to node 140+139\n",
      "Assigned 20 protos to node 035+034\n",
      "Assigned 20 protos to node 199+193\n",
      "Assigned 20 protos to node 129+117\n",
      "Assigned 20 protos to node 011+095\n",
      "Assigned 20 protos to node 013+088\n",
      "Assigned 20 protos to node 175+181\n",
      "Assigned 20 protos to node 054+016\n",
      "Assigned 20 protos to node 199+197\n",
      "Assigned 20 protos to node 193+195\n",
      "Assigned 20 protos to node 129+133\n",
      "Assigned 20 protos to node 117+114\n",
      "Assigned 20 protos to node 011+026\n",
      "Assigned 20 protos to node 095+096\n",
      "Assigned 20 protos to node 013+012\n",
      "Assigned 40 protos to node 175+168+173+183\n",
      "Assigned 20 protos to node 054+015\n",
      "Assigned 20 protos to node 199+196\n",
      "Assigned 20 protos to node 129+021\n",
      "Assigned 20 protos to node 133+130\n",
      "Assigned 20 protos to node 117+115\n",
      "Assigned 20 protos to node 011+049\n",
      "Assigned 20 protos to node 026+010\n",
      "Assigned 20 protos to node 095+098\n",
      "Assigned 20 protos to node 096+097\n",
      "Assigned 20 protos to node 175+162\n",
      "Assigned 20 protos to node 168+177\n",
      "Assigned 20 protos to node 173+161\n",
      "Assigned 20 protos to node 183+159\n",
      "Assigned 20 protos to node 129+128\n",
      "Assigned 20 protos to node 021+148\n",
      "Assigned 20 protos to node 133+076\n",
      "Assigned 20 protos to node 130+120\n",
      "Assigned 20 protos to node 117+116\n",
      "Assigned 20 protos to node 115+119\n",
      "Assigned 20 protos to node 011+009\n",
      "Assigned 20 protos to node 026+027\n",
      "Assigned 20 protos to node 175+167\n",
      "Assigned 20 protos to node 162+180\n",
      "Assigned 20 protos to node 168+200\n",
      "Assigned 20 protos to node 177+178\n",
      "Assigned 20 protos to node 173+179\n",
      "Assigned 20 protos to node 161+166\n",
      "Assigned 20 protos to node 183+184\n",
      "Assigned 20 protos to node 129+127\n",
      "Assigned 20 protos to node 128+131\n",
      "Assigned 20 protos to node 133+132\n",
      "Assigned 20 protos to node 175+169\n",
      "Assigned 20 protos to node 168+170\n",
      "Assigned 20 protos to node 173+172\n",
      "Assigned 20 protos to node 129+123\n",
      "Assigned 20 protos to node 128+124\n",
      "Assigned 20 protos to node 133+122\n",
      "Assigned 30 protos to node 175+165+182\n",
      "Assigned 20 protos to node 129+125\n",
      "Assigned 20 protos to node 123+113\n",
      "Assigned 20 protos to node 128+126\n",
      "Assigned 20 protos to node 175+160\n",
      "Assigned 30 protos to node 165+164+163\n",
      "Assigned 20 protos to node 175+176\n",
      "Assigned 20 protos to node 160+109\n",
      "Assigned 20 protos to node 165+158\n",
      "Assigned 20 protos to node 175+174\n",
      "Output shape:  torch.Size([228, 20, 26, 26])\n",
      "26\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    device_ids = [torch.cuda.current_device()]\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    device_ids = []\n",
    "\n",
    "# args_file = open(os.path.join(run_path, 'metadata', 'args.pickle'), 'rb')\n",
    "# args = pickle.load(args_file)\n",
    "\n",
    "# ckpt_file_name = 'net_overspecific_pruned_replaced_thresh=0.5_last'\n",
    "# ckpt_file_name = 'net_trained_last'\n",
    "# ckpt_file_name = 'net_trained_10'\n",
    "# ckpt_file_name = 'net_pretrained'\n",
    "epoch = ckpt_file_name.split('_')[-1]\n",
    "\n",
    "ckpt_path = os.path.join(run_path, 'checkpoints', ckpt_file_name)\n",
    "checkpoint = torch.load(ckpt_path, map_location=device)\n",
    "\n",
    "if ckpt_file_name != 'net_trained_last':\n",
    "    print('\\n', (10*'-')+'WARNING: Not using the final trained model'+(10*'-'), '\\n')\n",
    "\n",
    "# Obtain the dataset and dataloaders\n",
    "temp = args.leave_out_classes\n",
    "args.leave_out_classes = '' # NOTE: because here we need to load the entire dataloader, and filter out the classes later\n",
    "trainloader, trainloader_pretraining, trainloader_normal, trainloader_normal_augment, projectloader, testloader, test_projectloader, classes = get_dataloaders(args, device)\n",
    "args.leave_out_classes = temp\n",
    "\n",
    "print(args.batch_size, trainloader.batch_size)\n",
    "\n",
    "if len(classes)<=20:\n",
    "    if args.validation_size == 0.:\n",
    "        print(\"Classes: \", testloader.dataset.class_to_idx, flush=True)\n",
    "    else:\n",
    "        print(\"Classes: \", str(classes), flush=True)\n",
    "\n",
    "# Create a convolutional network based on arguments and add 1x1 conv layer\n",
    "feature_net, add_on_layers, pool_layer, classification_layers, num_prototypes = get_network(len(classes), args, root=root)\n",
    "   \n",
    "# Create a PIP-Net\n",
    "net = PIPNet(num_classes=len(classes),\n",
    "                    num_prototypes=num_prototypes,\n",
    "                    feature_net = feature_net,\n",
    "                    args = args,\n",
    "                    add_on_layers = add_on_layers,\n",
    "                    pool_layer = pool_layer,\n",
    "                    classification_layers = classification_layers,\n",
    "                    num_parent_nodes = len(root.nodes_with_children()),\n",
    "                    root = root\n",
    "                    )\n",
    "net = net.to(device=device)\n",
    "net = nn.DataParallel(net, device_ids = device_ids)    \n",
    "net.load_state_dict(checkpoint['model_state_dict'],strict=True)\n",
    "# print(net.eval())\n",
    "criterion = nn.NLLLoss(reduction='mean').to(device)\n",
    "\n",
    "# Forward one batch through the backbone to get the latent output size\n",
    "with torch.no_grad():\n",
    "    xs1, _, _ = next(iter(trainloader))\n",
    "    xs1 = xs1.to(device)\n",
    "    _, proto_features, _, _ = net(xs1)\n",
    "    wshape = proto_features['root'].shape[-1]\n",
    "    args.wshape = wshape #needed for calculating image patch size\n",
    "    print(\"Output shape: \", proto_features['root'].shape, flush=True)\n",
    "    \n",
    "print(args.wshape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9b5b65-35ae-441d-939f-76897b2dad35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6339634b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "W&B syncing is set to <code>`offline`<code> in this directory.  <br/>Run <code>`wandb online`<code> or set <code>WANDB_MODE=online<code> to enable cloud syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import wandb\n",
    "from util.log import Log\n",
    "os.environ['WANDB_DISABLED'] = 'true'\n",
    "wandb_run = wandb.init(project=\"pipnet\", name=os.path.basename(args.log_dir), config=vars(args), reinit=False)\n",
    "log = Log(args.log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47e8df17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chosen network is convnext\n",
      "-------------------------Not using OOD data-------------------------\n"
     ]
    }
   ],
   "source": [
    "optimizer_net, optimizer_classifier, params_to_freeze, params_to_train, params_backbone = get_optimizer_nn(net, args)            \n",
    "scheduler_net = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer_net, T_max=len(trainloader)*args.epochs, eta_min=args.lr_net/100.)\n",
    "if args.epochs<=30:\n",
    "    scheduler_classifier = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer_classifier, T_0=5, eta_min=0.001, T_mult=1, verbose=False)\n",
    "else:\n",
    "    scheduler_classifier = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer_classifier, T_0=10, eta_min=0.001, T_mult=1, verbose=False)\n",
    "\n",
    "    \n",
    "if args.OOD_dataset:\n",
    "    trainloader_OOD, trainloader_pretraining_OOD, trainloader_normal_OOD, trainloader_normal_augment_OOD, projectloader_OOD, testloader_OOD, test_projectloader_OOD, _ = get_dataloaders(args, device, OOD=True)\n",
    "    print('-'*25 + 'Using OOD data' + '-'*25)\n",
    "else:\n",
    "    trainloader_OOD = trainloader_pretraining_OOD = trainloader_normal_OOD = trainloader_normal_augment_OOD = projectloader_OOD = testloader_OOD = test_projectloader_OOD = None\n",
    "    print('-'*25 + 'Not using OOD data' + '-'*25)\n",
    "    \n",
    "if ('focal_loss' in args) and (args.focal_loss == 'y'):\n",
    "    from util.custom_losses import WeightedCrossEntropyLoss, WeightedNLLLoss, FocalLossWrapper\n",
    "    criterion = FocalLossWrapper(device=device, alpha=1, gamma=args.focal_loss_gamma, reduction='mean').to(device)\n",
    "else:\n",
    "    from util.custom_losses import WeightedCrossEntropyLoss, WeightedNLLLoss, FocalLossWrapper\n",
    "    criterion = WeightedNLLLoss(device=device).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb43785a-cf12-4460-bae5-efe9cf9d332d",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b84a48d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_heatmap(latent_activation, input_image):\n",
    "    image_a = latent_activation.cpu().numpy()\n",
    "    image_a = (image_a - image_a.min()) / (image_a.max() - image_a.min())\n",
    "\n",
    "    input_image = (input_image - input_image.min()) / (input_image.max() - input_image.min())\n",
    "    image_b = input_image.permute(1, 2, 0).cpu().numpy()\n",
    "    \n",
    "    reshaped_image_a = np.array(Image.fromarray((image_a[0] * 255).astype('uint8')).resize((input_image.shape[-1], input_image.shape[-1])))\n",
    "    normalized_heatmap = (reshaped_image_a - np.min(reshaped_image_a)) / (np.max(reshaped_image_a) - np.min(reshaped_image_a))\n",
    "    \n",
    "    heatmap_colormap = plt.get_cmap('jet')\n",
    "    heatmap_colored = heatmap_colormap(normalized_heatmap)\n",
    "    \n",
    "    heatmap_colored_uint8 = (heatmap_colored[:, :, :3] * 255).astype(np.uint8)\n",
    "    image_a_heatmap_pillow = Image.fromarray(heatmap_colored_uint8)\n",
    "    image_b_pillow = Image.fromarray((image_b * 255).astype('uint8'))\n",
    "    \n",
    "    result_image = Image.blend(image_b_pillow, image_a_heatmap_pillow, alpha=0.3)\n",
    "    \n",
    "    return np.array(result_image)\n",
    "\n",
    "\n",
    "def get_heatmap_uninterpolated(latent_activation, input_image):\n",
    "    image_a = latent_activation.cpu().numpy()\n",
    "    image_a = (image_a - image_a.min()) / (image_a.max() - image_a.min())\n",
    "\n",
    "    input_image = (input_image - input_image.min()) / (input_image.max() - input_image.min())\n",
    "    image_b = input_image.permute(1, 2, 0).cpu().numpy()\n",
    "    \n",
    "    reshaped_image_a = np.array(Image.fromarray((image_a[0] * 255).astype('uint8')).resize((input_image.shape[-1], input_image.shape[-1]), \\\n",
    "                                                                                          resample=Image.NEAREST ))\n",
    "    normalized_heatmap = (reshaped_image_a - np.min(reshaped_image_a)) / (np.max(reshaped_image_a) - np.min(reshaped_image_a))\n",
    "    \n",
    "    heatmap_colormap = plt.get_cmap('jet')\n",
    "    heatmap_colored = heatmap_colormap(normalized_heatmap)\n",
    "    \n",
    "    heatmap_colored_uint8 = (heatmap_colored[:, :, :3] * 255).astype(np.uint8)\n",
    "    image_a_heatmap_pillow = Image.fromarray(heatmap_colored_uint8)\n",
    "    image_b_pillow = Image.fromarray((image_b * 255).astype('uint8'))\n",
    "    \n",
    "    result_image = Image.blend(image_b_pillow, image_a_heatmap_pillow, alpha=0.3)\n",
    "    \n",
    "    return np.array(result_image)\n",
    "\n",
    "def get_bb_gaussian_threshold(latent_activation, sigma=1.0, percentile=97, extend_h=0, extend_w=0):\n",
    "    # latent_activation -> []\n",
    "    upscaled_similarity = get_upscaled_activation_uninterpolated(latent_activation, \\\n",
    "                                                                 image_size=(args.image_size, args.image_size))\n",
    "    upscaled_similarity = minmaxscale(upscaled_similarity)\n",
    "    upscaled_similarity = gaussian(upscaled_similarity, sigma=sigma)\n",
    "    upscaled_similarity = threshold_local(upscaled_similarity, block_size=15, method='mean')\n",
    "    h_min, h_max, w_min, w_max = find_top_percentile_bbox(upscaled_similarity ,percentile=97)\n",
    "    h_min = max(0, h_min-extend_h)\n",
    "    h_max = min(upscaled_similarity.shape[0], h_max+extend_h)\n",
    "    w_min = max(0, w_min-extend_w)\n",
    "    w_max = min(upscaled_similarity.shape[1], w_max+extend_w)\n",
    "    return h_min, h_max, w_min, w_max\n",
    "\n",
    "\n",
    "def minmaxscale(tensor):\n",
    "    return (tensor - tensor.min()) / (tensor.max() - tensor.min())\n",
    "\n",
    "from torch.utils.data import DataLoader, SequentialSampler\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def unshuffle_dataloader(dataloader):\n",
    "    if type(dataloader.dataset) == ImageFolder:\n",
    "        dataset = dataloader.dataset\n",
    "    else:\n",
    "        dataset = dataloader.dataset.dataset.dataset\n",
    "    new_dataloader = DataLoader(\n",
    "        dataset=dataset,\n",
    "        batch_size=dataloader.batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=dataloader.num_workers,\n",
    "        pin_memory=dataloader.pin_memory,\n",
    "        drop_last=dataloader.drop_last,\n",
    "        timeout=dataloader.timeout,\n",
    "        worker_init_fn=dataloader.worker_init_fn,\n",
    "        multiprocessing_context=dataloader.multiprocessing_context,\n",
    "        generator=dataloader.generator,\n",
    "        prefetch_factor=dataloader.prefetch_factor,\n",
    "        persistent_workers=dataloader.persistent_workers\n",
    "    )\n",
    "    return new_dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d7da75-8319-4629-8865-668f55c0a8f0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Fine accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0c293507-c348-4fec-9669-938143926a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'cl_weight' not in args:\n",
    "    args.cl_weight = 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1414fe0c-accf-4289-9b2f-9dac08326ffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Epoch0: 100% 21/21 [00:09<00:00,  2.21it/s, L:-0.461,LC:0.091, L_OVSP:-0.065, L_MASKL1:0.019, LA_PF:0.015, LT:-5.000, L_ORTH:0.005, LT_DESC:-5.000, L_OOD_ENT:-5.000, losses_used:MASK_PRUNING+MIN_CONT+AL_PF+KO+CL]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tFine accuracy: 0.908\n",
      "\tNode name: root, acc: 100.0, f1:100.0, samples: 2588, 021+004=2496/2496=1.0, 006+007=92/92=1.0\n",
      "\tNode name: 021+004, acc: 99.84, f1:99.84, samples: 2496, 021+001=1628/1632=1.0, 004+005=864/864=1.0\n",
      "\tNode name: 006+007, acc: 89.13, f1:89.11, samples: 92, fis_006_Lepisosteus_osseus=44/48=0.92, fis_007_Lepisosteus_platostomus=38/44=0.86\n",
      "\tNode name: 021+001, acc: 99.51, f1:99.54, samples: 1632, 021+034=1598/1606=1.0, fis_001_Alosa_chrysochloris=26/26=1.0\n",
      "\tNode name: 004+005, acc: 100.0, f1:100.0, samples: 864, fis_004_Esox_americanus=80/80=1.0, 005+016=784/784=1.0\n",
      "\tNode name: 021+034, acc: 100.0, f1:100.0, samples: 1606, 021+002=1228/1228=1.0, 034+036+037+035+033=378/378=1.0\n",
      "\tNode name: 005+016, acc: 100.0, f1:100.0, samples: 784, 005+015=652/652=1.0, 016+017=132/132=1.0\n",
      "\tNode name: 021+002, acc: 100.0, f1:100.0, samples: 1228, 021+024+025+031+027+019+020+026+022+032+018=1108/1108=1.0, 002+003=120/120=1.0\n",
      "\tNode name: 034+036+037+035+033, acc: 93.65, f1:93.64, samples: 378, fis_034_Noturus_flavus=68/80=0.85, fis_036_Noturus_miurus=76/80=0.95, fis_037_Noturus_nocturnus=74/76=0.97, fis_035_Noturus_gyrinus=74/80=0.93, fis_033_Noturus_exilis=62/62=1.0\n",
      "\tNode name: 005+015, acc: 100.0, f1:100.0, samples: 652, fis_005_Gambusia_affinis=80/80=1.0, 015+011=572/572=1.0\n",
      "\tNode name: 016+017, acc: 95.45, f1:95.44, samples: 132, fis_016_Morone_chrysops=78/80=0.98, fis_017_Morone_mississippiensis=48/52=0.92\n",
      "\tNode name: 021+024+025+031+027+019+020+026+022+032+018, acc: 88.99, f1:89.0, samples: 1108, 021+038=384/420=0.91, fis_024_Notropis_hudsonius=72/80=0.9, fis_025_Notropis_leuciodus=40/46=0.87, fis_031_Notropis_volucellus=58/72=0.81, fis_027_Notropis_percobromus=68/80=0.85, fis_019_Notropis_blennius=78/80=0.98, fis_020_Notropis_boops=72/80=0.9, fis_026_Notropis_nubilus=56/66=0.85, fis_022_Notropis_buchanani=50/52=0.96, fis_032_Notropis_wickliffi=30/52=0.58, fis_018_Notropis_atherinoides=78/80=0.98\n",
      "\tNode name: 002+003, acc: 96.67, f1:96.62, samples: 120, fis_002_Carassius_auratus=36/40=0.9, fis_003_Cyprinus_carpio=80/80=1.0\n",
      "\tNode name: 015+011, acc: 98.6, f1:98.57, samples: 572, 015+014+009+010+013+012+008=492/492=1.0, fis_011_Lepomis_gulosus=72/80=0.9\n",
      "\tNode name: 021+038, acc: 100.0, f1:100.0, samples: 420, 021+023=340/340=1.0, fis_038_Phenacobius_mirabilis=80/80=1.0\n",
      "\tNode name: 015+014+009+010+013+012+008, acc: 89.02, f1:88.92, samples: 492, fis_015_Lepomis_microlophus=26/42=0.62, fis_014_Lepomis_megalotis=72/80=0.9, fis_009_Lepomis_cyanellus=76/80=0.95, fis_010_Lepomis_gibbosus=76/80=0.95, fis_013_Lepomis_macrochirus=74/80=0.93, fis_012_Lepomis_humilis=70/80=0.88, fis_008_Lepomis_auritus=44/50=0.88\n",
      "\tNode name: 021+023, acc: 98.24, f1:98.24, samples: 340, 021+029=256/260=0.98, fis_023_Notropis_dorsalis=78/80=0.98\n",
      "\tNode name: 021+029, acc: 98.46, f1:98.46, samples: 260, 021+028=210/212=0.99, fis_029_Notropis_telescopus=46/48=0.96\n",
      "\tNode name: 021+028, acc: 100.0, f1:100.0, samples: 212, 021+030=132/132=1.0, fis_028_Notropis_stramineus=80/80=1.0\n",
      "\tNode name: 021+030, acc: 100.0, f1:100.0, samples: 132, fis_021_Notropis_buccatus=80/80=1.0, fis_030_Notropis_texanus=52/52=1.0\n"
     ]
    }
   ],
   "source": [
    "# testloader\n",
    "\n",
    "test_info, log_dict = test_pipnet(net, testloader, optimizer_net, optimizer_classifier, \\\n",
    "                                    scheduler_net, scheduler_classifier, criterion, 0, \\\n",
    "                                        args.epochs, device, pretrain=False, finetune=False, \\\n",
    "                                        test_loader_OOD=testloader_OOD, kernel_orth=args.kernel_orth == 'y', \\\n",
    "                                            tanh_desc=args.tanh_desc == 'y', align=args.align == 'y', uni=args.uni == 'y', align_pf=args.align_pf == 'y',\\\n",
    "                                            minmaximize=args.minmaximize == 'y', wandb_run=wandb_run, pretrain_epochs=args.epochs_pretrain, log=log, \\\n",
    "                                          args=args, apply_overspecificity_mask=False, path_prob_softmax_tau=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "179f3017-a4a7-418a-8a25-496de314ceca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9080370942812983"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(test_info['fine_accuracy'], 4)\n",
    "test_info['fine_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7f88bcde-7e7b-4f26-8d70-4b3cac5c874d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.2361, 1.7321])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([5, 3]).pow(1/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10f6a5d-d5b6-41f3-9da2-9ca115fa5855",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Geometric mean accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c4bff115-cb1e-44af-b08e-8126a4e40d97",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21/21 [00:13<00:00,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: tensor(0.9096)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "leafname_to_depth = {}\n",
    "leafname_to_idx = testloader.dataset.class_to_idx\n",
    "\n",
    "\n",
    "\n",
    "def get_node_depth(node):\n",
    "    depth = 0\n",
    "    while node.parent:\n",
    "        depth += 1\n",
    "        node = node.parent\n",
    "    return depth\n",
    "\n",
    "for leaf_name in root.leaf_descendents:\n",
    "    leaf_node = root.get_node(leaf_name)\n",
    "    leafname_to_depth[leaf_name] = get_node_depth(leaf_node)\n",
    "\n",
    "def get_path_prob_list(out_probs, data_idx, root, leaf_node):\n",
    "    node = leaf_node\n",
    "    path_prob_list = []\n",
    "    while node.parent:\n",
    "        parent = node.parent\n",
    "        child_class_idx = parent.children_to_labels[node.name]\n",
    "        path_prob_list.append(out_probs[parent.name][data_idx, child_class_idx])\n",
    "        node = parent\n",
    "    return path_prob_list\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, (xs, ys) in tqdm(enumerate(testloader), total=len(testloader)):\n",
    "\n",
    "        features, proto_features, pooled, out = net(xs)\n",
    "        out_probs = {}\n",
    "        for node_name, output_logits in out.items():\n",
    "            out_probs[node_name] = torch.softmax(output_logits, dim=1)\n",
    "\n",
    "        batch_leaf_probs_list = []\n",
    "        for data_idx in range(xs.shape[0]):\n",
    "            leaf_probs = [0 for _ in range(len(leafname_to_idx))]\n",
    "            for leafname, class_idx in leafname_to_idx.items():\n",
    "                leaf_node = root.get_node(leafname)\n",
    "                path_prob_list = get_path_prob_list(out_probs, data_idx, root, leaf_node)\n",
    "                depth = leafname_to_depth[leafname]\n",
    "                leaf_probs[class_idx] = torch.tensor([prob**(1/depth) for prob in path_prob_list]).prod()\n",
    "            batch_leaf_probs_list.append(torch.tensor(leaf_probs))\n",
    "        batch_leaf_probs = torch.stack(batch_leaf_probs_list)\n",
    "\n",
    "        correct += (batch_leaf_probs.argmax(dim=1) == ys).sum()\n",
    "        total += ys.shape[0]\n",
    "\n",
    "print('Accuracy:', correct / total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "01c792a6-0923-4dc6-8b39-b3e92d47d71e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(testloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "449a56f4-b599-437e-b216-bd9ff22b2a61",
   "metadata": {},
   "source": [
    "# Leave one out accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de75a068-908d-454a-b5a4-1b5b3e441cae",
   "metadata": {},
   "source": [
    "## Remove classes from dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "caed7bac-9b1a-4f96-8945-75427c659692",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testloader Unique Labels: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189}\n",
      "testloader total_samples: 5512\n",
      "classes_to_keep ['cub_198_Rock_Wren']\n",
      "leave_out_loader Unique Labels: {187}\n",
      "leave_out_loader total_samples: 30\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Sampler, SubsetRandomSampler\n",
    "\n",
    "def create_filtered_dataloader(dataloader, new_sampler, batch_size):\n",
    "    if type(dataloader.dataset) == ImageFolder:\n",
    "        dataset = dataloader.dataset\n",
    "    else:\n",
    "        dataset = dataloader.dataset.dataset.dataset\n",
    "    new_dataloader = DataLoader(\n",
    "        dataset=dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        sampler=new_sampler,\n",
    "        num_workers=dataloader.num_workers,\n",
    "        pin_memory=dataloader.pin_memory,\n",
    "        drop_last=dataloader.drop_last,\n",
    "        timeout=dataloader.timeout,\n",
    "        worker_init_fn=dataloader.worker_init_fn,\n",
    "        multiprocessing_context=dataloader.multiprocessing_context,\n",
    "        generator=dataloader.generator,\n",
    "        prefetch_factor=dataloader.prefetch_factor,\n",
    "        persistent_workers=dataloader.persistent_workers\n",
    "    )\n",
    "    return new_dataloader\n",
    "\n",
    "leave_out_loader = testloader\n",
    "# leave_out_loader = test_projectloader\n",
    "unique_labels = set()\n",
    "total_samples = 0\n",
    "for xs, ys in testloader:\n",
    "    unique_labels.update(ys.tolist())\n",
    "    total_samples += xs.shape[0]\n",
    "print(\"testloader Unique Labels:\", unique_labels)\n",
    "print(\"testloader total_samples:\", total_samples)\n",
    "\n",
    "# leave_out_classes = args.leave_out_classes.split(',')[2]\n",
    "\n",
    "class_of_interest = 1\n",
    "classes_to_keep = [leave_out_classes[class_of_interest]]\n",
    "\n",
    "# classes_to_keep = [leave_out_classes[1], leave_out_classes[6], leave_out_classes[8]]\n",
    "# classes_to_keep = [leave_out_classes[0], leave_out_classes[1], leave_out_classes[2], leave_out_classes[3], leave_out_classes[6], leave_out_classes[7]]\n",
    "\n",
    "\n",
    "# classes_to_keep = leave_out_classes\n",
    "\n",
    "# leave_out_classes = ['cub_093_Clark_Nutcracker']\n",
    "\n",
    "print('classes_to_keep', classes_to_keep)\n",
    "idx_of_classes_to_keep = set()\n",
    "name2label = leave_out_loader.dataset.class_to_idx # param\n",
    "label2name = {label:name for name, label in name2label.items()}\n",
    "for label in label2name:\n",
    "    # NOTE: Keeping the left out classes here\n",
    "    if label2name[label] in classes_to_keep:\n",
    "        idx_of_classes_to_keep.add(label)\n",
    "\n",
    "target_indices = []\n",
    "for i in range(len(leave_out_loader.dataset)):\n",
    "    *_, label = leave_out_loader.dataset[i]\n",
    "    if label in idx_of_classes_to_keep:\n",
    "        target_indices.append(i)\n",
    "sampler = SubsetRandomSampler(target_indices)\n",
    "to_shuffle = False\n",
    "    \n",
    "leave_out_loader = create_filtered_dataloader(leave_out_loader, sampler, batch_size=1) # dataloader.batch_size\n",
    "unique_labels = set()\n",
    "total_samples = 0\n",
    "for xs, ys in leave_out_loader:\n",
    "    unique_labels.update(ys.tolist())\n",
    "    total_samples += xs.shape[0]\n",
    "print(\"leave_out_loader Unique Labels:\", unique_labels)\n",
    "print(\"leave_out_loader total_samples:\", total_samples)\n",
    "\n",
    "\n",
    "\n",
    "# print('Leave out classes', args.leave_out_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f2b4aae4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cub_030_Fish_Crow',\n",
       " 'cub_198_Rock_Wren',\n",
       " 'cub_014_Indigo_Bunting',\n",
       " 'cub_185_Bohemian_Waxwing']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# leave_out_loader.dataset.class_to_idx\n",
    "leave_out_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b79ee1fb-5bdf-44d1-ad64-bdeafa2b449f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'cl_weight' not in args:\n",
    "    args.cl_weight = 2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d710c6-2358-4550-974a-7b0526ceb117",
   "metadata": {},
   "source": [
    "## Check each left out image path probability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915e59f4-b165-4779-8a34-5ce2d4b353f5",
   "metadata": {},
   "source": [
    "This is to see what is the probablity for an image of a left out class at each node along the path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b0fde7ba-258c-42b8-86e9-ce9edccf4443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground truth: cub_198_Rock_Wren\n",
      "Predicted: cub_160_Black_throated_Blue_Warbler\n",
      "Node of certainty: 199+198\n",
      "(cub_160_Black_throated_Blue_Warbler|1.00|6.13) <- (160+109|1.00|6.86) <- (175+160|0.98|10.14) <- (175+165+182|1.00|13.18) <- (175+169|1.00|10.76) <- (175+167|1.00|15.67) <- (175+162|0.99|7.69) <- (175+168+173+183|1.00|9.36) <- (175+181|1.00|8.32) <- (175+099|1.00|9.46) <- (175+020|0.99|5.73) <- (129+175|1.00|14.52) <- (129+054|1.00|13.03) <- (129+035|1.00|9.22) <- (129+104|0.96|4.26) <- (129+118|0.99|4.82) <- (129+199|1.00|9.36) <- (129+136|0.87|3.44) <- (129+107|1.00|10.94) <- (129+018|0.99|5.12) <- (129+043|1.00|13.68) <- (129+192|0.99|6.14) <- (129+065|0.85|3.84) <- (129+024+067|1.00|19.70)\n",
      "--------------------------------------------------\n",
      "Ground truth: cub_198_Rock_Wren\n",
      "Predicted: cub_091_Mockingbird\n",
      "Node of certainty: 199+198\n",
      "(cub_091_Mockingbird|0.96|5.31) <- (150+091|1.00|8.73) <- (150+149|1.00|8.27) <- (150+019|0.98|4.81) <- (199+150|1.00|14.05) <- (199+186|0.92|3.13) <- (129+199|1.00|11.96) <- (129+136|0.61|2.25) <- (129+107|1.00|10.82) <- (129+018|0.92|3.66) <- (129+043|1.00|11.97) <- (129+192|0.99|4.67) <- (129+065|0.84|3.65) <- (129+024+067|1.00|15.75)\n",
      "--------------------------------------------------\n",
      "Ground truth: cub_198_Rock_Wren\n",
      "Predicted: cub_196_House_Wren\n",
      "Node of certainty: 199+198\n",
      "(cub_196_House_Wren|0.98|5.69) <- (199+196|1.00|7.00) <- (199+197|1.00|7.52) <- (199+193|1.00|8.13) <- (199+194|1.00|16.09) <- (199+198|1.00|15.07) <- (199+028|1.00|11.72) <- (199+094|0.91|4.32) <- (199+150|1.00|13.02) <- (199+186|0.65|2.22) <- (129+199|1.00|12.83) <- (129+136|1.00|8.53) <- (129+107|1.00|11.46) <- (129+018|0.96|4.06) <- (129+043|1.00|10.56) <- (129+192|1.00|10.65) <- (129+065|0.76|3.94) <- (129+024+067|1.00|16.67)\n",
      "--------------------------------------------------\n",
      "Ground truth: cub_198_Rock_Wren\n",
      "Predicted: cub_015_Lazuli_Bunting\n",
      "Node of certainty: 199+198\n",
      "(cub_015_Lazuli_Bunting|0.97|4.89) <- (054+015|1.00|8.48) <- (054+016|1.00|18.53) <- (054+014|1.00|11.45) <- (054+057|1.00|8.81) <- (054+140|0.99|6.52) <- (129+054|0.76|2.29) <- (129+035|1.00|8.72) <- (129+104|0.97|4.67) <- (129+118|1.00|6.10) <- (129+199|1.00|9.58) <- (129+136|1.00|9.82) <- (129+107|1.00|12.07) <- (129+018|1.00|6.49) <- (129+043|1.00|14.79) <- (129+192|1.00|5.75) <- (129+065|0.93|4.40) <- (129+024+067|1.00|15.96)\n",
      "--------------------------------------------------\n",
      "Ground truth: cub_198_Rock_Wren\n",
      "Predicted: cub_174_Palm_Warbler\n",
      "Node of certainty: 199+198\n",
      "(cub_174_Palm_Warbler|0.93|4.83) <- (175+174|1.00|6.88) <- (175+176|1.00|9.09) <- (175+160|1.00|9.21) <- (175+165+182|1.00|11.12) <- (175+169|1.00|7.74) <- (175+167|1.00|12.86) <- (175+162|0.59|4.47) <- (175+168+173+183|1.00|7.83) <- (175+181|0.99|5.48) <- (175+099|1.00|7.70) <- (175+020|0.63|2.70) <- (129+175|1.00|9.56) <- (129+054|0.95|6.41) <- (129+035|1.00|8.79) <- (129+104|0.97|4.42) <- (129+118|0.94|3.87) <- (129+199|1.00|10.98) <- (129+136|0.98|6.54) <- (129+107|1.00|10.88) <- (129+018|0.98|4.90) <- (129+043|1.00|12.42) <- (129+192|1.00|5.93) <- (129+065|0.94|4.35) <- (129+024+067|1.00|14.04)\n",
      "--------------------------------------------------\n",
      "Ground truth: cub_198_Rock_Wren\n",
      "Predicted: cub_196_House_Wren\n",
      "Node of certainty: 199+198\n",
      "(cub_196_House_Wren|0.95|4.50) <- (199+196|1.00|6.31) <- (199+197|0.99|5.91) <- (199+193|0.68|4.55) <- (199+194|1.00|17.21) <- (199+198|1.00|13.74) <- (199+028|1.00|11.91) <- (199+094|0.99|7.76) <- (199+150|1.00|13.63) <- (199+186|0.97|4.90) <- (129+199|1.00|12.60) <- (129+136|1.00|7.66) <- (129+107|1.00|11.49) <- (129+018|1.00|7.27) <- (129+043|1.00|14.65) <- (129+192|1.00|8.46) <- (129+065|0.57|3.39) <- (129+024+067|1.00|19.06)\n",
      "--------------------------------------------------\n",
      "Ground truth: cub_198_Rock_Wren\n",
      "Predicted: cub_150_Sage_Thrasher\n",
      "Node of certainty: 199+198\n",
      "(cub_150_Sage_Thrasher|1.00|6.52) <- (150+091|1.00|8.67) <- (150+149|0.99|5.11) <- (150+019|0.78|3.71) <- (199+150|1.00|14.68) <- (199+186|0.98|4.17) <- (129+199|1.00|14.30) <- (129+136|1.00|9.72) <- (129+107|1.00|10.18) <- (129+018|1.00|6.54) <- (129+043|1.00|9.45) <- (129+192|1.00|7.87) <- (129+065|0.93|4.48) <- (129+024+067|1.00|18.69)\n",
      "--------------------------------------------------\n",
      "Ground truth: cub_198_Rock_Wren\n",
      "Predicted: cub_069_Rufous_Hummingbird\n",
      "Node of certainty: 199+198\n",
      "(cub_069_Rufous_Hummingbird|0.97|5.23) <- (067+069|1.00|7.12) <- (067+068|1.00|10.69) <- (067+070|0.40|2.78) <- (129+024+067|1.00|9.76)\n",
      "--------------------------------------------------\n",
      "Ground truth: cub_198_Rock_Wren\n",
      "Predicted: cub_184_Louisiana_Waterthrush\n",
      "Node of certainty: 199+198\n",
      "(cub_184_Louisiana_Waterthrush|1.00|5.84) <- (183+184|1.00|9.29) <- (183+159|0.96|5.52) <- (175+168+173+183|0.98|4.51) <- (175+181|1.00|8.25) <- (175+099|1.00|8.36) <- (175+020|1.00|7.05) <- (129+175|1.00|15.22) <- (129+054|1.00|12.17) <- (129+035|1.00|9.41) <- (129+104|0.94|4.48) <- (129+118|0.70|2.37) <- (129+199|1.00|10.61) <- (129+136|1.00|9.95) <- (129+107|1.00|11.97) <- (129+018|1.00|5.69) <- (129+043|1.00|14.97) <- (129+192|1.00|11.20) <- (129+065|0.97|4.68) <- (129+024+067|1.00|17.77)\n",
      "--------------------------------------------------\n",
      "Ground truth: cub_198_Rock_Wren\n",
      "Predicted: cub_196_House_Wren\n",
      "Node of certainty: 199+198\n",
      "(cub_196_House_Wren|0.85|4.66) <- (199+196|1.00|6.83) <- (199+197|1.00|7.19) <- (199+193|1.00|11.46) <- (199+194|1.00|18.44) <- (199+198|1.00|15.98) <- (199+028|1.00|13.74) <- (199+094|1.00|10.47) <- (199+150|1.00|13.66) <- (199+186|0.97|3.84) <- (129+199|1.00|14.52) <- (129+136|1.00|9.97) <- (129+107|1.00|10.64) <- (129+018|0.98|4.39) <- (129+043|1.00|12.17) <- (129+192|1.00|10.57) <- (129+065|0.97|4.53) <- (129+024+067|1.00|17.79)\n",
      "--------------------------------------------------\n",
      "Ground truth: cub_198_Rock_Wren\n",
      "Predicted: cub_067_Anna_Hummingbird\n",
      "Node of certainty: 199+198\n",
      "(cub_067_Anna_Hummingbird|0.97|4.58) <- (067+069|1.00|8.06) <- (067+068|1.00|10.58) <- (067+070|0.96|5.41) <- (129+024+067|1.00|15.12)\n",
      "--------------------------------------------------\n",
      "Ground truth: cub_198_Rock_Wren\n",
      "Predicted: cub_196_House_Wren\n",
      "Node of certainty: 199+198\n",
      "(cub_196_House_Wren|0.98|5.66) <- (199+196|1.00|6.28) <- (199+197|1.00|7.18) <- (199+193|1.00|7.39) <- (199+194|1.00|17.86) <- (199+198|1.00|13.28) <- (199+028|1.00|11.13) <- (199+094|0.90|4.87) <- (199+150|1.00|12.93) <- (199+186|0.98|4.60) <- (129+199|1.00|12.51) <- (129+136|0.95|6.43) <- (129+107|1.00|8.44) <- (129+018|0.56|1.97) <- (129+043|1.00|7.43) <- (129+192|0.99|5.77) <- (129+065|0.94|4.28) <- (129+024+067|1.00|15.51)\n",
      "--------------------------------------------------\n",
      "Ground truth: cub_198_Rock_Wren\n",
      "Predicted: cub_091_Mockingbird\n",
      "Node of certainty: 199+198\n",
      "(cub_091_Mockingbird|0.99|5.45) <- (150+091|1.00|8.77) <- (150+149|1.00|8.44) <- (150+019|0.99|5.37) <- (199+150|1.00|14.35) <- (199+186|0.42|3.19) <- (129+199|1.00|14.41) <- (129+136|1.00|6.12) <- (129+107|1.00|11.95) <- (129+018|1.00|6.86) <- (129+043|1.00|11.45) <- (129+192|1.00|12.35) <- (129+065|0.94|4.30) <- (129+024+067|1.00|18.70)\n",
      "--------------------------------------------------\n",
      "Ground truth: cub_198_Rock_Wren\n",
      "Predicted: cub_196_House_Wren\n",
      "Node of certainty: 199+198\n",
      "(cub_196_House_Wren|0.99|5.53) <- (199+196|1.00|6.85) <- (199+197|0.98|5.02) <- (199+193|1.00|10.31) <- (199+194|1.00|17.60) <- (199+198|1.00|15.06) <- (199+028|1.00|9.67) <- (199+094|1.00|8.34) <- (199+150|1.00|15.60) <- (199+186|0.75|3.22) <- (129+199|1.00|8.43) <- (129+136|0.74|4.32) <- (129+107|1.00|8.80) <- (129+018|0.99|6.76) <- (129+043|1.00|10.66) <- (129+192|0.92|4.12) <- (129+065|0.94|4.46) <- (129+024+067|1.00|18.62)\n",
      "--------------------------------------------------\n",
      "Ground truth: cub_198_Rock_Wren\n",
      "Predicted: cub_069_Rufous_Hummingbird\n",
      "Node of certainty: 199+198\n",
      "(cub_069_Rufous_Hummingbird|0.83|3.26) <- (067+069|1.00|7.20) <- (067+068|1.00|9.93) <- (067+070|0.50|3.25) <- (129+024+067|1.00|17.13)\n",
      "--------------------------------------------------\n",
      "Ground truth: cub_198_Rock_Wren\n",
      "Predicted: cub_199_Winter_Wren\n",
      "Node of certainty: 199+198\n",
      "(cub_199_Winter_Wren|0.98|5.44) <- (199+196|0.99|6.12) <- (199+197|1.00|6.63) <- (199+193|1.00|8.88) <- (199+194|1.00|17.39) <- (199+198|1.00|13.21) <- (199+028|1.00|12.67) <- (199+094|1.00|8.38) <- (199+150|1.00|14.46) <- (199+186|0.47|4.32) <- (129+199|1.00|13.79) <- (129+136|1.00|8.28) <- (129+107|1.00|11.98) <- (129+018|1.00|6.70) <- (129+043|1.00|8.33) <- (129+192|1.00|10.17) <- (129+065|0.77|3.44) <- (129+024+067|1.00|16.65)\n",
      "--------------------------------------------------\n",
      "Ground truth: cub_198_Rock_Wren\n",
      "Predicted: cub_199_Winter_Wren\n",
      "Node of certainty: 199+198\n",
      "(cub_199_Winter_Wren|0.99|5.25) <- (199+196|1.00|6.99) <- (199+197|1.00|7.71) <- (199+193|1.00|12.00) <- (199+194|1.00|18.31) <- (199+198|1.00|15.85) <- (199+028|1.00|11.97) <- (199+094|1.00|9.49) <- (199+150|1.00|14.43) <- (199+186|0.98|4.06) <- (129+199|1.00|14.34) <- (129+136|1.00|9.10) <- (129+107|1.00|10.31) <- (129+018|1.00|8.94) <- (129+043|1.00|11.27) <- (129+192|1.00|9.09) <- (129+065|0.95|4.41) <- (129+024+067|1.00|17.22)\n",
      "--------------------------------------------------\n",
      "Ground truth: cub_198_Rock_Wren\n",
      "Predicted: cub_196_House_Wren\n",
      "Node of certainty: 199+198\n",
      "(cub_196_House_Wren|0.94|4.84) <- (199+196|0.99|5.83) <- (199+197|1.00|7.72) <- (199+193|1.00|12.10) <- (199+194|1.00|18.45) <- (199+198|1.00|16.01) <- (199+028|1.00|11.01) <- (199+094|1.00|7.40) <- (199+150|1.00|16.21) <- (199+186|1.00|6.02) <- (129+199|1.00|13.92) <- (129+136|1.00|9.75) <- (129+107|1.00|12.14) <- (129+018|0.90|3.18) <- (129+043|1.00|15.56) <- (129+192|1.00|9.96) <- (129+065|0.96|4.47) <- (129+024+067|1.00|16.91)\n",
      "--------------------------------------------------\n",
      "Ground truth: cub_198_Rock_Wren\n",
      "Predicted: cub_069_Rufous_Hummingbird\n",
      "Node of certainty: 199+198\n",
      "(cub_069_Rufous_Hummingbird|0.98|5.34) <- (067+069|1.00|8.11) <- (067+068|1.00|10.69) <- (067+070|0.84|4.34) <- (129+024+067|1.00|7.40)\n",
      "--------------------------------------------------\n",
      "Ground truth: cub_198_Rock_Wren\n",
      "Predicted: cub_150_Sage_Thrasher\n",
      "Node of certainty: 199+198\n",
      "(cub_150_Sage_Thrasher|1.00|6.43) <- (150+091|1.00|8.71) <- (150+149|1.00|8.51) <- (150+019|0.84|5.13) <- (199+150|1.00|12.36) <- (199+186|1.00|6.80) <- (129+199|1.00|14.26) <- (129+136|1.00|9.99) <- (129+107|1.00|11.20) <- (129+018|1.00|8.09) <- (129+043|1.00|10.43) <- (129+192|1.00|8.48) <- (129+065|0.95|4.68) <- (129+024+067|1.00|16.41)\n",
      "--------------------------------------------------\n",
      "Ground truth: cub_198_Rock_Wren\n",
      "Predicted: cub_069_Rufous_Hummingbird\n",
      "Node of certainty: 199+198\n",
      "(cub_069_Rufous_Hummingbird|0.81|3.53) <- (067+069|1.00|7.63) <- (067+068|1.00|9.35) <- (067+070|0.61|4.06) <- (129+024+067|1.00|17.47)\n",
      "--------------------------------------------------\n",
      "Ground truth: cub_198_Rock_Wren\n",
      "Predicted: cub_197_Marsh_Wren\n",
      "Node of certainty: 199+198\n",
      "(cub_197_Marsh_Wren|0.96|5.09) <- (199+197|0.99|7.13) <- (199+193|1.00|10.31) <- (199+194|1.00|18.41) <- (199+198|1.00|15.92) <- (199+028|1.00|12.46) <- (199+094|0.98|5.06) <- (199+150|1.00|11.43) <- (199+186|0.93|3.61) <- (129+199|1.00|13.56) <- (129+136|1.00|9.66) <- (129+107|1.00|11.96) <- (129+018|1.00|6.77) <- (129+043|1.00|12.32) <- (129+192|1.00|11.95) <- (129+065|0.95|4.44) <- (129+024+067|1.00|12.08)\n",
      "--------------------------------------------------\n",
      "Ground truth: cub_198_Rock_Wren\n",
      "Predicted: cub_199_Winter_Wren\n",
      "Node of certainty: 199+198\n",
      "(cub_199_Winter_Wren|0.99|5.61) <- (199+196|1.00|6.77) <- (199+197|1.00|7.76) <- (199+193|1.00|13.20) <- (199+194|1.00|18.50) <- (199+198|1.00|15.99) <- (199+028|1.00|11.49) <- (199+094|1.00|9.48) <- (199+150|1.00|13.66) <- (199+186|0.51|2.33) <- (129+199|1.00|13.63) <- (129+136|1.00|7.83) <- (129+107|1.00|11.89) <- (129+018|1.00|7.78) <- (129+043|1.00|15.42) <- (129+192|1.00|9.86) <- (129+065|0.97|4.78) <- (129+024+067|1.00|11.14)\n",
      "--------------------------------------------------\n",
      "Ground truth: cub_198_Rock_Wren\n",
      "Predicted: cub_199_Winter_Wren\n",
      "Node of certainty: 199+198\n",
      "(cub_199_Winter_Wren|0.94|3.87) <- (199+196|1.00|6.99) <- (199+197|1.00|7.64) <- (199+193|1.00|9.70) <- (199+194|1.00|16.76) <- (199+198|1.00|14.71) <- (199+028|1.00|10.57) <- (199+094|1.00|12.13) <- (199+150|1.00|16.24) <- (199+186|1.00|8.47) <- (129+199|1.00|12.34) <- (129+136|1.00|9.32) <- (129+107|1.00|10.72) <- (129+018|0.68|3.60) <- (129+043|1.00|13.56) <- (129+192|1.00|10.28) <- (129+065|0.86|3.58) <- (129+024+067|1.00|15.95)\n",
      "--------------------------------------------------\n",
      "Ground truth: cub_198_Rock_Wren\n",
      "Predicted: cub_196_House_Wren\n",
      "Node of certainty: 199+198\n",
      "(cub_196_House_Wren|0.99|5.69) <- (199+196|1.00|6.97) <- (199+197|1.00|7.16) <- (199+193|1.00|13.47) <- (199+194|1.00|17.47) <- (199+198|1.00|15.33) <- (199+028|1.00|13.63) <- (199+094|1.00|13.13) <- (199+150|1.00|13.64) <- (199+186|1.00|9.31) <- (129+199|1.00|13.93) <- (129+136|1.00|10.03) <- (129+107|1.00|11.73) <- (129+018|0.42|2.38) <- (129+043|1.00|14.46) <- (129+192|1.00|10.37) <- (129+065|0.95|4.61) <- (129+024+067|1.00|18.29)\n",
      "--------------------------------------------------\n",
      "Ground truth: cub_198_Rock_Wren\n",
      "Predicted: cub_102_Western_Wood_Pewee\n",
      "Node of certainty: 199+198\n",
      "(cub_102_Western_Wood_Pewee|0.93|3.27) <- (040+102|1.00|5.69) <- (043+040|1.00|12.91) <- (043+042|1.00|11.67) <- (043+078|0.97|3.97) <- (129+043|1.00|11.01) <- (129+192|1.00|8.45) <- (129+065|0.95|4.52) <- (129+024+067|1.00|19.56)\n",
      "--------------------------------------------------\n",
      "Ground truth: cub_198_Rock_Wren\n",
      "Predicted: cub_196_House_Wren\n",
      "Node of certainty: 199+198\n",
      "(cub_196_House_Wren|0.99|5.70) <- (199+196|0.99|6.43) <- (199+197|0.84|3.88) <- (199+193|1.00|8.77) <- (199+194|1.00|15.94) <- (199+198|1.00|15.58) <- (199+028|1.00|12.68) <- (199+094|1.00|10.76) <- (199+150|1.00|15.17) <- (199+186|1.00|10.84) <- (129+199|1.00|14.30) <- (129+136|1.00|9.17) <- (129+107|1.00|12.09) <- (129+018|0.90|3.82) <- (129+043|1.00|12.39) <- (129+192|1.00|9.79) <- (129+065|0.96|4.77) <- (129+024+067|1.00|15.24)\n",
      "--------------------------------------------------\n",
      "Ground truth: cub_198_Rock_Wren\n",
      "Predicted: cub_194_Cactus_Wren\n",
      "Node of certainty: 199+198\n",
      "(cub_194_Cactus_Wren|0.79|3.88) <- (199+194|1.00|18.06) <- (199+198|1.00|15.94) <- (199+028|1.00|11.88) <- (199+094|1.00|9.49) <- (199+150|1.00|15.61) <- (199+186|0.94|3.41) <- (129+199|1.00|13.40) <- (129+136|1.00|9.90) <- (129+107|1.00|11.63) <- (129+018|1.00|7.55) <- (129+043|1.00|13.51) <- (129+192|1.00|10.01) <- (129+065|0.96|4.42) <- (129+024+067|1.00|20.20)\n",
      "--------------------------------------------------\n",
      "Ground truth: cub_198_Rock_Wren\n",
      "Predicted: cub_150_Sage_Thrasher\n",
      "Node of certainty: 199+198\n",
      "(cub_150_Sage_Thrasher|1.00|6.35) <- (150+091|1.00|7.95) <- (150+149|1.00|8.53) <- (150+019|0.97|4.93) <- (199+150|1.00|13.30) <- (199+186|1.00|8.38) <- (129+199|1.00|14.49) <- (129+136|1.00|8.32) <- (129+107|1.00|10.09) <- (129+018|0.98|4.74) <- (129+043|0.99|5.25) <- (129+192|1.00|7.94) <- (129+065|0.62|3.39) <- (129+024+067|1.00|15.85)\n",
      "--------------------------------------------------\n",
      "Ground truth: cub_198_Rock_Wren\n",
      "Predicted: cub_196_House_Wren\n",
      "Node of certainty: 199+198\n",
      "(cub_196_House_Wren|0.99|5.62) <- (199+196|1.00|6.93) <- (199+197|0.99|6.52) <- (199+193|1.00|13.07) <- (199+194|1.00|16.94) <- (199+198|1.00|15.05) <- (199+028|1.00|11.35) <- (199+094|1.00|11.00) <- (199+150|1.00|14.07) <- (199+186|0.99|4.41) <- (129+199|1.00|12.50) <- (129+136|1.00|8.72) <- (129+107|1.00|11.84) <- (129+018|1.00|5.74) <- (129+043|1.00|15.90) <- (129+192|1.00|10.32) <- (129+065|0.95|4.61) <- (129+024+067|1.00|16.72)\n",
      "--------------------------------------------------\n",
      "Accuracy: tensor(0.)\n"
     ]
    }
   ],
   "source": [
    "leafname_to_depth = {}\n",
    "leafname_to_idx = testloader.dataset.class_to_idx\n",
    "\n",
    "name2label = leave_out_loader.dataset.class_to_idx\n",
    "label2name = {label:name for name, label in name2label.items()}\n",
    "\n",
    "def get_node_depth(node):\n",
    "    depth = 0\n",
    "    while node.parent:\n",
    "        depth += 1\n",
    "        node = node.parent\n",
    "    return depth\n",
    "\n",
    "for leaf_name in root.leaf_descendents:\n",
    "    leaf_node = root.get_node(leaf_name)\n",
    "    leafname_to_depth[leaf_name] = get_node_depth(leaf_node)\n",
    "\n",
    "def get_path_prob_list(out_probs, data_idx, root, leaf_node):\n",
    "    node = leaf_node\n",
    "    path_prob_list = []\n",
    "    while node.parent:\n",
    "        parent = node.parent\n",
    "        child_class_idx = parent.children_to_labels[node.name]\n",
    "        path_prob_list.append(out_probs[parent.name][data_idx, child_class_idx])\n",
    "        node = parent\n",
    "    return path_prob_list\n",
    "\n",
    "def get_path_node_and_prob_list(out, out_probs, data_idx, root, leaf_node):\n",
    "    node = leaf_node\n",
    "    path_node_and_prob_list = []\n",
    "    while node.parent:\n",
    "        parent = node.parent\n",
    "        child_class_idx = parent.children_to_labels[node.name]\n",
    "        path_node_and_prob_list.append((node, out_probs[parent.name][data_idx, child_class_idx], \\\n",
    "                                        out[parent.name][data_idx, child_class_idx]))\n",
    "        node = parent\n",
    "    return path_node_and_prob_list\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, (xs, ys) in enumerate(leave_out_loader):\n",
    "\n",
    "        print('Ground truth:', label2name[ys.item()])\n",
    "\n",
    "        features, proto_features, pooled, out = net(xs)\n",
    "        out_probs = {}\n",
    "        for node_name, output_logits in out.items():\n",
    "            out_probs[node_name] = torch.softmax(output_logits, dim=1)\n",
    "\n",
    "        batch_leaf_probs_list = []\n",
    "        for data_idx in range(xs.shape[0]):\n",
    "            leaf_probs = [0 for _ in range(len(leafname_to_idx))]\n",
    "            leafname_to_path_node_and_prob_list = {}\n",
    "            for leafname, class_idx in leafname_to_idx.items():\n",
    "                leaf_node = root.get_node(leafname)\n",
    "                \n",
    "                path_node_and_prob_list = get_path_node_and_prob_list(out, out_probs, data_idx, root, leaf_node)\n",
    "                depth = leafname_to_depth[leafname]\n",
    "                leaf_probs[class_idx] = torch.tensor([prob for _, prob, _ in path_node_and_prob_list]).prod()\n",
    "\n",
    "                leafname_to_path_node_and_prob_list[leafname] = path_node_and_prob_list\n",
    "            batch_leaf_probs_list.append(torch.tensor(leaf_probs))\n",
    "        batch_leaf_probs = torch.stack(batch_leaf_probs_list)\n",
    "\n",
    "        predicted_label = np.argmax(leaf_probs)\n",
    "        print('Predicted:', label2name[predicted_label])\n",
    "\n",
    "        predicted_node = root.get_node(label2name[predicted_label])\n",
    "        ground_truth_parent_node = root.get_node(label2name[ys.item()]).parent\n",
    "\n",
    "        print('Node of certainty:', ground_truth_parent_node.name)\n",
    "\n",
    "        print(\" <- \".join([f\"({node.name}|{prob:.2f}|{logit:.2f})\" for node, prob, logit in leafname_to_path_node_and_prob_list[predicted_node.name]]))\n",
    "\n",
    "        correct += (batch_leaf_probs.argmax(dim=1) == ys).sum()\n",
    "        total += ys.shape[0]\n",
    "\n",
    "        print('-'*50)\n",
    "\n",
    "print('Accuracy:', correct / total)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "225c9fc1-d569-4dd5-a7dc-400d38ae22b2",
   "metadata": {},
   "source": [
    "## Logit distribution for descendant and non-descendant species for each node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a125c908-34e3-44e3-b854-9880e86ed66b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [03:24<00:00,  8.17s/it]\n"
     ]
    }
   ],
   "source": [
    "leafname_to_depth = {}\n",
    "leafname_to_idx = testloader.dataset.class_to_idx\n",
    "idx_to_leafname = {v: k for k, v in leafname_to_idx.items()}\n",
    "\n",
    "\n",
    "def get_node_depth(node):\n",
    "    depth = 0\n",
    "    while node.parent:\n",
    "        depth += 1\n",
    "        node = node.parent\n",
    "    return depth\n",
    "\n",
    "for leaf_name in root.leaf_descendents:\n",
    "    leaf_node = root.get_node(leaf_name)\n",
    "    leafname_to_depth[leaf_name] = get_node_depth(leaf_node)\n",
    "\n",
    "def get_path_prob_list(out_probs, data_idx, root, leaf_node):\n",
    "    node = leaf_node\n",
    "    path_prob_list = []\n",
    "    while node.parent:\n",
    "        parent = node.parent\n",
    "        child_class_idx = parent.children_to_labels[node.name]\n",
    "        path_prob_list.append(out_probs[parent.name][data_idx, child_class_idx])\n",
    "        node = parent\n",
    "    return path_prob_list\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "# maps node_name to list of descendant_logits and non_descendant_logits\n",
    "logits = defaultdict(lambda: {'descendants': [], 'non_descendants': []})\n",
    "avg_proto_activations = defaultdict(lambda: {'descendants': [], 'non_descendants': []})\n",
    "with torch.no_grad():\n",
    "    for i, (xs, ys) in tqdm(enumerate(testloader), total=len(testloader)):\n",
    "        features, proto_features, pooled, out = net(xs)\n",
    "        for data_idx in range(xs.shape[0]):\n",
    "            gt_label = ys[data_idx].item()\n",
    "            gt_leafname = idx_to_leafname[gt_label]\n",
    "            for node in root.nodes_with_children():\n",
    "                logit_of_prediction = out[node.name][data_idx, :].max().item()\n",
    "                if gt_leafname in node.leaf_descendents:\n",
    "                    logits[node.name]['descendants'].append(logit_of_prediction)\n",
    "                else:\n",
    "                    logits[node.name]['non_descendants'].append(logit_of_prediction)\n",
    "            for node in root.nodes_with_children():\n",
    "                predicted_child_class_idx = out[node.name][data_idx, :].argmax().item()\n",
    "                classification_weights = getattr(net.module, '_'+node.name+'_classification').weight\n",
    "                relevant_proto_idx = torch.nonzero(classification_weights[predicted_child_class_idx, :] > 1e-3).squeeze(-1)\n",
    "                avg_proto_activation = pooled[node.name][data_idx, relevant_proto_idx].mean().item()\n",
    "                if gt_leafname in node.leaf_descendents:\n",
    "                    avg_proto_activations[node.name]['descendants'].append(logit_of_prediction)\n",
    "                else:\n",
    "                    avg_proto_activations[node.name]['non_descendants'].append(logit_of_prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7cce6dc6-72b9-4974-b50f-6595ef329f13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      "5.0477318378714156 1.2585128255402978\n",
      "--------------------\n",
      "129+024+067\n",
      "5.0601713153027905 1.2566105986275846\n",
      "4.488784651954969 1.2163287815325041\n",
      "--------------------\n",
      "089+046\n",
      "4.488784651954969 1.2163287815325041\n",
      "5.0601713153027905 1.2566105986275846\n",
      "--------------------\n",
      "129+065\n",
      "5.0959177575262125 1.2347552260401542\n",
      "4.742254922456652 1.3606380296276812\n",
      "--------------------\n",
      "024+051\n",
      "4.70015399679979 1.4284949443882586\n",
      "5.083247190158478 1.234333428892655\n",
      "--------------------\n",
      "067+070\n",
      "5.175004968047142 1.0762006595350702\n",
      "5.044899349811125 1.2621247395693267\n",
      "--------------------\n",
      "089+090\n",
      "4.297007675965627 1.3277076223929092\n",
      "5.055993659168985 1.2552348479272455\n",
      "--------------------\n",
      "046+087\n",
      "4.680561627944311 1.0595032147045271\n",
      "5.0517725958676785 1.2599330576201204\n",
      "--------------------\n",
      "129+192\n",
      "5.220714366304225 1.1484278170381197\n",
      "4.537705987563789 1.4201200198197712\n",
      "--------------------\n",
      "065+006\n",
      "4.2995412587195405 1.450479215649153\n",
      "5.146885921198508 1.196210293467683\n",
      "--------------------\n",
      "024+031\n",
      "4.562042067727774 1.518064961644608\n",
      "5.084815356740028 1.2285942036432536\n",
      "--------------------\n",
      "051+052\n",
      "5.150168699026108 0.9570693251497286\n",
      "5.0454520857685665 1.2643098682594478\n",
      "--------------------\n",
      "067+068\n",
      "5.394042281309764 0.9414216797385131\n",
      "5.041983416641344 1.2623034121315508\n",
      "--------------------\n",
      "129+043\n",
      "5.264140212436175 1.124592869333662\n",
      "4.5805625845846265 1.3976622651199655\n",
      "--------------------\n",
      "192+081\n",
      "4.751988972667978 1.2898068831284815\n",
      "5.0677229786725 1.2538548657782134\n",
      "--------------------\n",
      "065+144\n",
      "4.369301482162351 1.4255047733347324\n",
      "5.109651535749435 1.223562274029851\n",
      "--------------------\n",
      "006+071\n",
      "4.124761568463367 1.4970320452323091\n",
      "5.079606186514637 1.2372233608886416\n",
      "--------------------\n",
      "024+086\n",
      "4.137606394760925 1.5189075264738867\n",
      "5.096255628933489 1.2242459340823746\n",
      "--------------------\n",
      "031+004\n",
      "5.619341645921979 0.8552829374254814\n",
      "5.035876227037774 1.2627808490869672\n",
      "--------------------\n",
      "051+053\n",
      "5.183081563313802 0.963818744309246\n",
      "5.045485162236997 1.2627019607228427\n",
      "--------------------\n",
      "067+069\n",
      "5.416936228672664 1.023102212483644\n",
      "5.0436686934385335 1.2602574859805094\n",
      "--------------------\n",
      "129+018\n",
      "5.2558115514768575 1.1329846118663494\n",
      "4.693863789892734 1.3767828686064778\n",
      "--------------------\n",
      "043+078\n",
      "5.361805017131406 1.0159731586510272\n",
      "5.029908666655741 1.2685600310451555\n",
      "--------------------\n",
      "192+036\n",
      "4.872463106809549 1.2346791589545938\n",
      "5.054296580480358 1.2589227566978833\n",
      "--------------------\n",
      "081+083\n",
      "4.592159954706828 1.342919326459065\n",
      "5.060476295624994 1.253691942040248\n",
      "--------------------\n",
      "065+084\n",
      "4.539842868371616 1.302493934269879\n",
      "5.072064161125018 1.2512026638678262\n",
      "--------------------\n",
      "144+147\n",
      "4.163672633718646 1.536010167902607\n",
      "5.082574073147284 1.2333998906197572\n",
      "--------------------\n",
      "006+058\n",
      "4.461107144432683 1.3327075055572355\n",
      "5.061232480407868 1.2535261796312576\n",
      "--------------------\n",
      "071+072\n",
      "3.42964737812678 1.5764243185889208\n",
      "5.065539076973521 1.2429019827393573\n",
      "--------------------\n",
      "024+001\n",
      "4.09381769890766 1.5226375474504845\n",
      "5.092862869716746 1.226382084185358\n",
      "--------------------\n",
      "031+032\n",
      "5.783376621036995 0.7505461765122802\n",
      "5.036622653300591 1.2613366315266907\n",
      "--------------------\n",
      "051+050\n",
      "5.145931581656138 1.0511706020957816\n",
      "5.046651136362413 1.2605623915015094\n",
      "--------------------\n",
      "129+107\n",
      "5.258694024661694 1.1334574015577885\n",
      "4.693118356574138 1.3733570501100452\n",
      "--------------------\n",
      "043+042\n",
      "5.389666725686714 1.0080644592090016\n",
      "5.03638741891297 1.2643892334241116\n",
      "--------------------\n",
      "078+038\n",
      "5.320363652305443 1.0262255734705399\n",
      "5.0417160422256435 1.2624930989045577\n",
      "--------------------\n",
      "192+191\n",
      "4.994271412599001 1.2961026350892777\n",
      "5.0491148639486285 1.257495304850176\n",
      "--------------------\n",
      "036+188\n",
      "4.590273865063986 1.024843590783353\n",
      "5.0527662249529355 1.2599198221586452\n",
      "--------------------\n",
      "081+082\n",
      "4.4303888320922855 1.3811088637329925\n",
      "5.061470925537123 1.2521909199674135\n",
      "--------------------\n",
      "065+061\n",
      "4.747106878002684 1.270186648842239\n",
      "5.058991835427199 1.2566769843955572\n",
      "--------------------\n",
      "084+063\n",
      "3.7616251718323186 1.1142932404740775\n",
      "5.060218310357232 1.2533802552408486\n",
      "--------------------\n",
      "144+143\n",
      "3.988123807161214 1.5019128193544435\n",
      "5.083297155234462 1.233836580675267\n",
      "--------------------\n",
      "006+008\n",
      "4.661429267376661 1.267405959326827\n",
      "5.054579150790082 1.257284511706685\n",
      "--------------------\n",
      "024+100\n",
      "4.283763160232369 1.5421626771215236\n",
      "5.066330592149564 1.2449738462863733\n",
      "--------------------\n",
      "001+045\n",
      "3.882946042691247 1.4722333031192123\n",
      "5.0732128767722795 1.2412727388819753\n",
      "--------------------\n",
      "031+033\n",
      "5.934998011184951 0.44942349753400335\n",
      "5.038131855435051 1.26102978915725\n",
      "--------------------\n",
      "129+136\n",
      "5.319535542789573 1.0883793838164157\n",
      "4.726196128330608 1.3658026353629413\n",
      "--------------------\n",
      "107+151\n",
      "4.871202308994366 1.322452566996615\n",
      "5.064149119061845 1.2511352425371995\n",
      "--------------------\n",
      "043+040\n",
      "5.448679359591737 0.9803096179215343\n",
      "5.036745950510206 1.2634852534766552\n",
      "--------------------\n",
      "078+041\n",
      "5.407647171047296 1.0629483758813654\n",
      "5.041825058477602 1.2606127405220477\n",
      "--------------------\n",
      "192+187\n",
      "4.41741594257234 1.3331534442661752\n",
      "5.056897115936688 1.255062026707546\n",
      "--------------------\n",
      "191+189\n",
      "5.753797781467438 0.7325300739385011\n",
      "5.0399614863278055 1.2608857791083277\n",
      "--------------------\n",
      "081+080\n",
      "4.328587293624878 1.4437087353194678\n",
      "5.0556461211903425 1.254030688694497\n",
      "--------------------\n",
      "082+079\n",
      "4.532190370559692 1.3076319696524996\n",
      "5.053405441693628 1.2567856625897031\n",
      "--------------------\n",
      "065+066\n",
      "4.8213693906935 1.1843595743719484\n",
      "5.053587855023422 1.2598336971025321\n",
      "--------------------\n",
      "061+064\n",
      "4.5750653902689615 1.4349368363621804\n",
      "5.052933596282301 1.2554438480198182\n",
      "--------------------\n",
      "144+142\n",
      "4.144345310310389 1.4402243483744772\n",
      "5.072830587192056 1.243754872472133\n",
      "--------------------\n",
      "006+005\n",
      "5.013712247212728 1.0336754197814089\n",
      "5.048030692254947 1.260306185545567\n",
      "--------------------\n",
      "008+106\n",
      "4.309146287540595 1.3769329185728985\n",
      "5.0542201443164885 1.2554993536789552\n",
      "--------------------\n",
      "024+023\n",
      "4.489880204200745 1.6194086428323153\n",
      "5.0560518493476305 1.2504612977691496\n",
      "--------------------\n",
      "100+101\n",
      "3.949853549003601 1.3425019374226999\n",
      "5.057781986982253 1.2532836459964376\n",
      "--------------------\n",
      "001+003\n",
      "3.913686513900757 1.5414964790158803\n",
      "5.066130803304568 1.2449077885827489\n",
      "--------------------\n",
      "129+199\n",
      "5.331980622371897 1.0817389694471669\n",
      "4.739625499435544 1.3600602019673127\n",
      "--------------------\n",
      "136+085\n",
      "5.022201849768559 1.1986461208618264\n",
      "5.048300012680826 1.2598069246172607\n",
      "--------------------\n",
      "107+111\n",
      "4.4785355757783964 1.4006466534662307\n",
      "5.077049462969683 1.2437202651582815\n",
      "--------------------\n",
      "151+153\n",
      "5.403966218382869 0.9833333095747334\n",
      "5.034388972875786 1.2657131846821128\n",
      "--------------------\n",
      "043+037\n",
      "5.667209945876023 0.8345465712631662\n",
      "5.0377973502407425 1.261678461397429\n",
      "--------------------\n",
      "040+102\n",
      "5.131810009479523 1.0839449339324405\n",
      "5.046806546180937 1.2602682556416043\n",
      "--------------------\n",
      "078+077\n",
      "5.70672232417737 0.6782682397054848\n",
      "5.0406017372493634 1.2614532544387456\n",
      "--------------------\n",
      "192+190\n",
      "4.153703940116753 1.2108153319719828\n",
      "5.057404980355832 1.255542615546949\n",
      "--------------------\n",
      "065+062\n",
      "4.818025117620416 1.2188454394276544\n",
      "5.052365936058971 1.2588689673838436\n",
      "--------------------\n",
      "144+145\n",
      "4.245243382053215 1.4233798291197877\n",
      "5.065439259759486 1.2488292641122054\n",
      "--------------------\n",
      "006+007\n",
      "4.971821455394521 1.0066824819345856\n",
      "5.048202986649111 1.2599043987194345\n",
      "--------------------\n",
      "024+025\n",
      "4.822408340298212 1.4440421416094906\n",
      "5.049877775943541 1.25641996497859\n",
      "--------------------\n",
      "001+002\n",
      "4.130597187081973 1.6257234705645138\n",
      "5.057825029186046 1.2501360164810644\n",
      "--------------------\n",
      "129+118\n",
      "5.381158740190435 1.039438354464581\n",
      "4.786770290778263 1.3500937363302803\n",
      "--------------------\n",
      "199+186\n",
      "5.0657366735556515 1.2537746556080902\n",
      "5.0461428622443965 1.2589177602001504\n",
      "--------------------\n",
      "136+138\n",
      "4.93165735370583 1.2456457777799137\n",
      "5.049658562986669 1.2586349812334792\n",
      "--------------------\n",
      "107+073\n",
      "4.111445690904345 1.3510680571676421\n",
      "5.084815974209229 1.2402384749525825\n",
      "--------------------\n",
      "111+112\n",
      "5.763350172837575 0.5629490129814344\n",
      "5.039856360964231 1.2617842732684388\n",
      "--------------------\n",
      "151+157\n",
      "5.074864361502907 1.082212347467902\n",
      "5.047179342943711 1.2618408712589915\n",
      "--------------------\n",
      "153+154\n",
      "5.81072132239181 0.644360451588752\n",
      "5.035209974673497 1.2622690467255278\n",
      "--------------------\n",
      "043+039\n",
      "5.712608925227461 0.8397257637715521\n",
      "5.040661271119188 1.2603364975730573\n",
      "--------------------\n",
      "065+059\n",
      "4.930628074875361 1.198301655654514\n",
      "5.049434616681776 1.2592867874239189\n",
      "--------------------\n",
      "144+146\n",
      "4.248163783148433 1.419415409277303\n",
      "5.060854013211697 1.2514466649381635\n",
      "--------------------\n",
      "129+104\n",
      "5.381089174722528 1.042265645406869\n",
      "4.79253515783485 1.3470483789732814\n",
      "--------------------\n",
      "199+150\n",
      "5.151452822894705 1.2063890739186207\n",
      "5.039899638612096 1.2620153038518227\n",
      "--------------------\n",
      "186+185\n",
      "4.512867510318756 1.4038567683686363\n",
      "5.053618092393272 1.2555528650509058\n",
      "--------------------\n",
      "136+137\n",
      "4.817377129693826 1.3507319873565125\n",
      "5.050266922700956 1.2572255385693083\n",
      "--------------------\n",
      "107+093\n",
      "4.289117749532064 1.298357850721811\n",
      "5.068953791107317 1.2507817043419618\n",
      "--------------------\n",
      "073+074\n",
      "3.6672655443350473 1.3777880671095113\n",
      "5.062924056802483 1.2486756455477868\n",
      "--------------------\n",
      "151+156\n",
      "4.605121818243289 0.8949569783342549\n",
      "5.051865350231979 1.26068213135078\n",
      "--------------------\n",
      "157+152\n",
      "5.48091300059173 1.0656471675711656\n",
      "5.043044933671801 1.2596238479581403\n",
      "--------------------\n",
      "153+155\n",
      "5.69223337658381 0.7063753930255884\n",
      "5.040758503783018 1.261368218022748\n",
      "--------------------\n",
      "065+060\n",
      "4.855180694132435 1.3097433048958704\n",
      "5.0494589120144155 1.2579105152279142\n",
      "--------------------\n",
      "144+141\n",
      "3.967292042101844 1.4156968830197645\n",
      "5.059421907181961 1.251614740277592\n",
      "--------------------\n",
      "129+035\n",
      "5.383127587856882 1.0421726185853295\n",
      "4.7966106545066625 1.345077745521263\n",
      "--------------------\n",
      "199+094\n",
      "5.335949435109986 1.1113927939595873\n",
      "5.032944400591771 1.263828477289866\n",
      "--------------------\n",
      "150+019\n",
      "4.730863088268345 1.3049209738459517\n",
      "5.05466370892317 1.2565856547938918\n",
      "--------------------\n",
      "107+030\n",
      "4.478925182422002 1.294591402167397\n",
      "5.060390739698924 1.2547684400559636\n",
      "--------------------\n",
      "129+054\n",
      "5.397024179395871 1.0404634781413624\n",
      "4.819029767362609 1.334125182297324\n",
      "--------------------\n",
      "035+055\n",
      "5.213806547932118 1.0480799597095278\n",
      "5.042157607025575 1.2645906072916175\n",
      "--------------------\n",
      "199+028\n",
      "5.435580287518362 1.0493674782238758\n",
      "5.030152513110251 1.2643595545899011\n",
      "--------------------\n",
      "150+149\n",
      "5.213463510020396 1.0036319288365956\n",
      "5.045011919224677 1.2620851417789496\n",
      "--------------------\n",
      "107+029\n",
      "4.596377425723606 1.3052095702324558\n",
      "5.055223888239048 1.256355696337646\n",
      "--------------------\n",
      "129+175\n",
      "5.393979025725467 1.0343837402139926\n",
      "4.858481130256463 1.327930594587996\n",
      "--------------------\n",
      "054+140\n",
      "5.422483232399936 1.0896341149408315\n",
      "5.031191380412589 1.2628875884366755\n",
      "--------------------\n",
      "035+048\n",
      "5.2305102060305195 1.0753600731115105\n",
      "5.042653714273484 1.2628446240099627\n",
      "--------------------\n",
      "199+198\n",
      "5.608215772537958 0.8191255190091933\n",
      "5.025532361017403 1.2677052699604983\n",
      "--------------------\n",
      "150+091\n",
      "5.5081570744514465 0.9446896036112405\n",
      "5.042664795649332 1.2605970771339567\n",
      "--------------------\n",
      "107+108\n",
      "4.625418849786123 1.437543503422582\n",
      "5.052379449625839 1.2556107124962075\n",
      "--------------------\n",
      "129+011\n",
      "5.272105885238665 1.048467073128854\n",
      "4.994371829750617 1.297795838365384\n",
      "--------------------\n",
      "175+020\n",
      "5.539157491164749 0.9981166119779661\n",
      "4.95323099301358 1.2812035395546162\n",
      "--------------------\n",
      "054+057\n",
      "5.3591105872637606 0.9275140178698432\n",
      "5.039259736229358 1.2652398705841907\n",
      "--------------------\n",
      "140+017\n",
      "5.528832728835358 1.3107422498124564\n",
      "5.040016487177616 1.2561572930102467\n",
      "--------------------\n",
      "035+056\n",
      "5.12122173791521 1.069266374651893\n",
      "5.046525752475159 1.2613461604685223\n",
      "--------------------\n",
      "048+047\n",
      "5.392621433734893 1.0638550641393327\n",
      "5.0439362810570705 1.25996275171766\n",
      "--------------------\n",
      "199+194\n",
      "5.626442273457845 0.784187532455808\n",
      "5.02819547658005 1.2668368753363421\n",
      "--------------------\n",
      "129+121\n",
      "5.312909690274132 1.070598065071409\n",
      "5.010726452224975 1.2781820184700499\n",
      "--------------------\n",
      "011+013\n",
      "5.200380446699758 1.0043783338712038\n",
      "5.036301052810947 1.2747715838352223\n",
      "--------------------\n",
      "175+099\n",
      "5.548240122129751 0.9993628860879514\n",
      "4.955204511030881 1.279512912847365\n",
      "--------------------\n",
      "054+014\n",
      "5.442843953083301 0.9200966825527966\n",
      "5.039237952518454 1.2634381201920004\n",
      "--------------------\n",
      "140+139\n",
      "6.206406195958455 0.2465979296670683\n",
      "5.034980469293789 1.2592372916629386\n",
      "--------------------\n",
      "035+034\n",
      "5.340683326882831 0.952710051264621\n",
      "5.044562181195884 1.2610440959668912\n",
      "--------------------\n",
      "199+193\n",
      "5.591553156375885 0.7411264147832168\n",
      "5.0325186342579 1.266606488960589\n",
      "--------------------\n",
      "129+117\n",
      "5.297383768151897 1.0835822434252\n",
      "5.014646673492761 1.2762430128987108\n",
      "--------------------\n",
      "011+095\n",
      "5.097000312885182 1.0327969089836437\n",
      "5.044915956483977 1.2701444680564387\n",
      "--------------------\n",
      "013+088\n",
      "5.558604631313058 0.801754257844695\n",
      "5.03963470181613 1.262761875925307\n",
      "--------------------\n",
      "175+181\n",
      "5.550801328291376 1.0093159726688237\n",
      "4.95855036050094 1.277192615664967\n",
      "--------------------\n",
      "054+016\n",
      "5.421754975651586 0.9316023935163724\n",
      "5.0418037158940665 1.262121232690896\n",
      "--------------------\n",
      "199+197\n",
      "5.573941561910841 0.7064403037703856\n",
      "5.038997261116796 1.2637992734845154\n",
      "--------------------\n",
      "193+195\n",
      "5.61797054807345 0.7895700865428383\n",
      "5.041456283467138 1.2612716946241622\n",
      "--------------------\n",
      "129+133\n",
      "5.24826753558404 1.111677090429047\n",
      "5.02781425162074 1.2704449984084303\n",
      "--------------------\n",
      "117+114\n",
      "5.463777535626678 0.9640277754959384\n",
      "5.036332263301047 1.2636910826039713\n",
      "--------------------\n",
      "011+026\n",
      "4.803546113008894 1.0274380419734765\n",
      "5.055927833511841 1.2647196102057838\n",
      "--------------------\n",
      "095+096\n",
      "5.538414613539431 0.8711458927185709\n",
      "5.036904608072696 1.2635773917268573\n",
      "--------------------\n",
      "013+012\n",
      "5.4789363869598935 0.8907690610454901\n",
      "5.043305984728279 1.2609674666694128\n",
      "--------------------\n",
      "175+168+173+183\n",
      "5.547430207220356 1.015917470379301\n",
      "4.962769325910367 1.2759293707860047\n",
      "--------------------\n",
      "054+015\n",
      "5.173310608699404 0.9982104391928822\n",
      "5.046396383396163 1.260925062156033\n",
      "--------------------\n",
      "199+196\n",
      "5.45083886384964 0.7836270922548532\n",
      "5.043295590336806 1.2620297793582194\n",
      "--------------------\n",
      "129+021\n",
      "5.343303750708418 1.0533399496386915\n",
      "5.029635598309967 1.2677613728871764\n",
      "--------------------\n",
      "133+130\n",
      "5.080370222197638 1.1894585815417047\n",
      "5.046630016945174 1.2607632521777017\n",
      "--------------------\n",
      "117+115\n",
      "5.520198257560404 0.8830993606809329\n",
      "5.037485578167317 1.2634652592752273\n",
      "--------------------\n",
      "011+049\n",
      "4.5907195337702715 1.040581897913761\n",
      "5.0552321320010485 1.2603941733631308\n",
      "--------------------\n",
      "026+010\n",
      "5.014007952478197 0.9693622306488284\n",
      "5.048291622025858 1.262746332397439\n",
      "--------------------\n",
      "095+098\n",
      "5.310016198952993 0.8384595704120821\n",
      "5.0448453628778545 1.262055025626093\n",
      "--------------------\n",
      "096+097\n",
      "5.770684187695132 0.8418573838714033\n",
      "5.039909687011412 1.260002771139334\n",
      "--------------------\n",
      "175+162\n",
      "5.549044340848923 1.0118469629728228\n",
      "5.006595476221514 1.2678698363814582\n",
      "--------------------\n",
      "168+177\n",
      "5.418560628644351 1.0623601127534636\n",
      "5.037713172944627 1.261878875733117\n",
      "--------------------\n",
      "173+161\n",
      "5.618227784698074 0.9402358293309832\n",
      "5.031991084677839 1.262511567523175\n",
      "--------------------\n",
      "183+159\n",
      "5.631133980221218 1.0565758528558502\n",
      "5.0380479218235585 1.2593137898384177\n",
      "--------------------\n",
      "129+128\n",
      "5.480015126309653 0.8934274340548368\n",
      "5.026504375287277 1.2699633640462797\n",
      "--------------------\n",
      "021+148\n",
      "4.755444835623106 1.4220490721933023\n",
      "5.050948496003275 1.2562164173038963\n",
      "--------------------\n",
      "133+076\n",
      "5.075975835323334 1.2515285443275859\n",
      "5.0471032622604675 1.2586606117470978\n",
      "--------------------\n",
      "130+120\n",
      "5.089158995946248 1.0543585221641423\n",
      "5.047275926373893 1.260568074760615\n",
      "--------------------\n",
      "117+116\n",
      "5.788476733838097 0.6225028898399103\n",
      "5.039717176425967 1.2612682533320627\n",
      "--------------------\n",
      "115+119\n",
      "5.247294290312405 1.0155259785053699\n",
      "5.045609611571163 1.260675481618765\n",
      "--------------------\n",
      "011+009\n",
      "4.547358314869768 1.0307553856463072\n",
      "5.053145745419021 1.259665682227773\n",
      "--------------------\n",
      "026+027\n",
      "4.7268171866734825 0.8845675926797915\n",
      "5.051263547165597 1.2615578224305777\n",
      "--------------------\n",
      "175+167\n",
      "5.510832021855776 1.037011564308054\n",
      "5.015564615157717 1.2661916150067645\n",
      "--------------------\n",
      "162+180\n",
      "5.777044510841369 0.8096321134612129\n",
      "5.039705652915766 1.2602194792414187\n",
      "--------------------\n",
      "168+200\n",
      "4.964288522018475 1.1194719602018448\n",
      "5.0491012745505435 1.2606207451317502\n",
      "--------------------\n",
      "177+178\n",
      "6.1405287981033325 0.28524116819837425\n",
      "5.036515446783991 1.259719396833401\n",
      "--------------------\n",
      "173+179\n",
      "5.551203094171674 0.9450902339547957\n",
      "5.039469078916829 1.261333026038464\n",
      "--------------------\n",
      "161+166\n",
      "5.719332826339592 0.9237093089150686\n",
      "5.040465294992336 1.259693048993348\n",
      "--------------------\n",
      "183+184\n",
      "6.096902902921041 0.1578439438434148\n",
      "5.036185567896548 1.2604616406944262\n",
      "--------------------\n",
      "129+127\n",
      "5.565830748715847 0.9221960043240551\n",
      "5.034328571798946 1.263211789948032\n",
      "--------------------\n",
      "128+131\n",
      "5.379776710221748 0.8476740471863413\n",
      "5.040405055040025 1.2650934748132279\n",
      "--------------------\n",
      "133+132\n",
      "5.301839374171363 1.1869022755795924\n",
      "5.043513896472117 1.2592345743393585\n",
      "--------------------\n",
      "175+169\n",
      "5.458760072363586 1.0605379074531616\n",
      "5.021725421800151 1.2655187470191904\n",
      "--------------------\n",
      "168+170\n",
      "4.999370461803371 1.0688264288602742\n",
      "5.048255095012075 1.2603989374626312\n",
      "--------------------\n",
      "173+172\n",
      "5.376912186543147 1.0772074717679443\n",
      "5.044109163454632 1.2598846512544568\n",
      "--------------------\n",
      "129+123\n",
      "5.467336589043294 0.9073688127940349\n",
      "5.03926674109597 1.2631602918504161\n",
      "--------------------\n",
      "128+124\n",
      "5.484146860208404 0.8088314634783534\n",
      "5.040569577685542 1.2633030037710875\n",
      "--------------------\n",
      "133+122\n",
      "5.151461261510849 1.3171613882481839\n",
      "5.046590281485068 1.2578045892006011\n",
      "--------------------\n",
      "175+165+182\n",
      "5.4800931863162825 1.0632277034484106\n",
      "5.022933057287296 1.2643271269364325\n",
      "--------------------\n",
      "129+125\n",
      "5.552138340675224 0.9042535521623103\n",
      "5.04227429456215 1.2606989291217494\n",
      "--------------------\n",
      "123+113\n",
      "5.3672705221176145 0.9008211278661955\n",
      "5.044806730912003 1.2609447806213672\n",
      "--------------------\n",
      "128+126\n",
      "5.513708106676737 0.8391788480945178\n",
      "5.0426037057862505 1.2613957076738167\n",
      "--------------------\n",
      "175+160\n",
      "5.682045589357415 1.021845960930575\n",
      "5.0301087259990656 1.2599045325742697\n",
      "--------------------\n",
      "165+164+163\n",
      "5.0267597630620005 1.0484055243959247\n",
      "5.048198575441358 1.2627872450986102\n",
      "--------------------\n",
      "175+176\n",
      "6.152961646185981 0.30986582489970155\n",
      "5.0293860830303405 1.2601342663249908\n",
      "--------------------\n",
      "160+109\n",
      "4.963699061991805 1.2791405692724311\n",
      "5.048641050007285 1.2582571006622\n",
      "--------------------\n",
      "165+158\n",
      "5.0615764409303665 1.0023546354269866\n",
      "5.047579476135624 1.2610415975052356\n",
      "--------------------\n",
      "175+174\n",
      "6.118861977259318 0.3605989613763563\n",
      "5.0359439053029496 1.2597970810468533\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "# for node in root.nodes_with_children():\n",
    "#     print(node.name)\n",
    "#     print(np.mean(logits[node.name]['descendants']), np.std(logits[node.name]['descendants']))\n",
    "#     if node.name != 'root':\n",
    "#         print(np.mean(logits[node.name]['non_descendants']), np.std(logits[node.name]['non_descendants']))\n",
    "#     print('-'*20)\n",
    "\n",
    "for node in root.nodes_with_children():\n",
    "    print(node.name)\n",
    "    print(np.mean(avg_proto_activations[node.name]['descendants']), np.std(avg_proto_activations[node.name]['descendants']))\n",
    "    if node.name != 'root':\n",
    "        print(np.mean(avg_proto_activations[node.name]['non_descendants']), np.std(avg_proto_activations[node.name]['non_descendants']))\n",
    "    print('-'*20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d131c4ec-83d8-451a-b02c-42ed8841130a",
   "metadata": {},
   "source": [
    "## Leave out without mask pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7e724d2f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Epoch0: 100% 1/1 [00:00<00:00,  1.32it/s, L:0.146,LC:0.760, L_OVSP:-0.004, L_MASKL1:0.001, LA_PF:0.011, LT:-5.000, L_ORTH:0.001, LT_DESC:-5.000, L_OOD_ENT:-5.000, losses_used:MASK_PRUNING+MIN_CONT+AL_PF+KO+CL]\n",
      "/home/harishbabu/.conda/envs/hpnet4/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/harishbabu/.conda/envs/hpnet4/lib/python3.9/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tFine accuracy: 0.57\n",
      "\tNode name: root, acc: 100.0, f1:100.0, samples: 60, 129+024+067=60/60=1.0, 089+046=0/0=nan\n",
      "\tNode name: 129+024+067, acc: 86.67, f1:92.86, samples: 60, 129+065=52/60=0.87, 024+051=0/0=nan, 067+070=0/0=nan\n",
      "\tNode name: 129+065, acc: 100.0, f1:100.0, samples: 60, 129+192=60/60=1.0, 065+006=0/0=nan\n",
      "\tNode name: 129+192, acc: 100.0, f1:100.0, samples: 60, 129+043=60/60=1.0, 192+081=0/0=nan\n",
      "\tNode name: 129+043, acc: 70.0, f1:82.35, samples: 60, 129+018=42/60=0.7, 043+078=0/0=nan\n",
      "\tNode name: 129+018, acc: 100.0, f1:100.0, samples: 60, 129+107=60/60=1.0, cub_018_Spotted_Catbird=0/0=nan\n",
      "\tNode name: 129+107, acc: 96.67, f1:98.31, samples: 60, 129+136=0/0=nan, 107+151=58/60=0.97\n",
      "\tNode name: 107+151, acc: 100.0, f1:100.0, samples: 60, 107+111=60/60=1.0, 151+153=0/0=nan\n",
      "\tNode name: 107+111, acc: 96.67, f1:98.31, samples: 60, 107+073=0/0=nan, 111+112=58/60=0.97\n",
      "\tNode name: 111+112, acc: 0.0, f1:0.0, samples: 60, cub_111_Loggerhead_Shrike=0/0=nan, cub_112_Great_Grey_Shrike=0/60=0.0\n"
     ]
    }
   ],
   "source": [
    "# testloader\n",
    "\n",
    "test_info, log_dict = test_pipnet(net, leave_out_loader, optimizer_net, optimizer_classifier, \\\n",
    "                                    scheduler_net, scheduler_classifier, criterion, 0, \\\n",
    "                                        args.epochs, device, pretrain=False, finetune=False, \\\n",
    "                                        test_loader_OOD=testloader_OOD, kernel_orth=args.kernel_orth == 'y', \\\n",
    "                                            tanh_desc=args.tanh_desc == 'y', align=args.align == 'y', uni=args.uni == 'y', align_pf=args.align_pf == 'y',\\\n",
    "                                            minmaximize=args.minmaximize == 'y', wandb_run=wandb_run, pretrain_epochs=args.epochs_pretrain, log=log, \\\n",
    "                                          args=args, apply_overspecificity_mask=False, leave_out_classes=leave_out_classes, path_prob_softmax_tau=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0562137d-d40c-453a-b950-87626d5abcf1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cub_030_Fish_Crow',\n",
       " 'cub_198_Rock_Wren',\n",
       " 'cub_147_Least_Tern',\n",
       " 'cub_014_Indigo_Bunting',\n",
       " 'cub_083_White_breasted_Kingfisher',\n",
       " 'cub_138_Tree_Swallow',\n",
       " 'cub_185_Bohemian_Waxwing',\n",
       " 'cub_112_Great_Grey_Shrike']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(test_info['fine_accuracy'], 2)\n",
    "leave_out_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0ea6aab4-9851-4c8c-a7ed-60b0ff34c3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # test_info['node_accuracy'].values()\n",
    "\n",
    "# # print(leave_out_classes[class_of_interest])\n",
    "\n",
    "# # for key in test_info['node_accuracy']:\n",
    "# #     if leave_out_classes[class_of_interest] in modified_root.get_node(key).leaf_descendents:\n",
    "# #         print(key, test_info['node_accuracy'][key]['accuracy'])\n",
    "\n",
    "# print(leave_out_classes[class_of_interest])\n",
    "# leave_out_accuracy = 1\n",
    "# for key in test_info['node_accuracy']:\n",
    "#     if leave_out_classes[class_of_interest] in root.get_node(key).leaf_descendents:\n",
    "#         if not (leave_out_classes[class_of_interest] in [child.name for child in root.get_node(key).children]):\n",
    "#             leave_out_accuracy *= test_info['node_accuracy'][key]['accuracy'] / 100\n",
    "#         print(key, test_info['node_accuracy'][key]['accuracy'])\n",
    "\n",
    "# print(leave_out_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dec387d2-56a5-4046-b426-2721ed40d729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classes_to_keep ['cub_030_Fish_Crow']\n",
      "leave_out_loader Unique Labels: {28}\n",
      "leave_out_loader total_samples: 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Epoch0: 100% 1/1 [00:00<00:00,  1.82it/s, L:0.039,LC:0.626, L_OVSP:-0.006, L_MASKL1:0.001, LA_PF:0.012, LT:-5.000, L_ORTH:0.005, LT_DESC:-5.000, L_OOD_ENT:-5.000, losses_used:MASK_PRUNING+MIN_CONT+AL_PF+KO+CL]\n",
      "/home/harishbabu/.conda/envs/hpnet4/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/harishbabu/.conda/envs/hpnet4/lib/python3.9/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tFine accuracy: 0.5333\n",
      "\tNode name: root, acc: 96.67, f1:98.31, samples: 60, 129+024+067=58/60=0.97, 089+046=0/0=nan\n",
      "\tNode name: 129+024+067, acc: 63.33, f1:77.55, samples: 60, 129+065=38/60=0.63, 024+051=0/0=nan, 067+070=0/0=nan\n",
      "\tNode name: 129+065, acc: 86.67, f1:92.86, samples: 60, 129+192=52/60=0.87, 065+006=0/0=nan\n",
      "\tNode name: 129+192, acc: 100.0, f1:100.0, samples: 60, 129+043=60/60=1.0, 192+081=0/0=nan\n",
      "\tNode name: 129+043, acc: 100.0, f1:100.0, samples: 60, 129+018=60/60=1.0, 043+078=0/0=nan\n",
      "\tNode name: 129+018, acc: 96.67, f1:98.31, samples: 60, 129+107=58/60=0.97, cub_018_Spotted_Catbird=0/0=nan\n",
      "\tNode name: 129+107, acc: 83.33, f1:90.91, samples: 60, 129+136=0/0=nan, 107+151=50/60=0.83\n",
      "\tNode name: 107+151, acc: 100.0, f1:100.0, samples: 60, 107+111=60/60=1.0, 151+153=0/0=nan\n",
      "\tNode name: 107+111, acc: 100.0, f1:100.0, samples: 60, 107+073=60/60=1.0, 111+112=0/0=nan\n",
      "\tNode name: 107+073, acc: 100.0, f1:100.0, samples: 60, 107+093=60/60=1.0, 073+074=0/0=nan\n",
      "\tNode name: 107+093, acc: 100.0, f1:100.0, samples: 60, 107+030=60/60=1.0, cub_093_Clark_Nutcracker=0/0=nan\n",
      "\tNode name: 107+030, acc: 0.0, f1:0.0, samples: 60, 107+029=0/0=nan, cub_030_Fish_Crow=0/60=0.0\n",
      "cub_030_Fish_Crow 0.53 ----------\n",
      "\n",
      "\n",
      "classes_to_keep ['cub_198_Rock_Wren']\n",
      "leave_out_loader Unique Labels: {187}\n",
      "leave_out_loader total_samples: 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Epoch0: 100% 1/1 [00:00<00:00,  1.84it/s, L:0.044,LC:0.554, L_OVSP:-0.005, L_MASKL1:0.001, LA_PF:0.010, LT:-5.000, L_ORTH:0.005, LT_DESC:-5.000, L_OOD_ENT:-5.000, losses_used:MASK_PRUNING+MIN_CONT+AL_PF+KO+CL]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tFine accuracy: 0.5333\n",
      "\tNode name: root, acc: 100.0, f1:100.0, samples: 60, 129+024+067=60/60=1.0, 089+046=0/0=nan\n",
      "\tNode name: 129+024+067, acc: 83.33, f1:90.91, samples: 60, 129+065=50/60=0.83, 024+051=0/0=nan, 067+070=0/0=nan\n",
      "\tNode name: 129+065, acc: 100.0, f1:100.0, samples: 60, 129+192=60/60=1.0, 065+006=0/0=nan\n",
      "\tNode name: 129+192, acc: 100.0, f1:100.0, samples: 60, 129+043=60/60=1.0, 192+081=0/0=nan\n",
      "\tNode name: 129+043, acc: 90.0, f1:94.74, samples: 60, 129+018=54/60=0.9, 043+078=0/0=nan\n",
      "\tNode name: 129+018, acc: 100.0, f1:100.0, samples: 60, 129+107=60/60=1.0, cub_018_Spotted_Catbird=0/0=nan\n",
      "\tNode name: 129+107, acc: 100.0, f1:100.0, samples: 60, 129+136=60/60=1.0, 107+151=0/0=nan\n",
      "\tNode name: 129+136, acc: 100.0, f1:100.0, samples: 60, 129+199=60/60=1.0, 136+085=0/0=nan\n",
      "\tNode name: 129+199, acc: 80.0, f1:88.89, samples: 60, 129+118=0/0=nan, 199+186=48/60=0.8\n",
      "\tNode name: 199+186, acc: 100.0, f1:100.0, samples: 60, 199+150=60/60=1.0, 186+185=0/0=nan\n",
      "\tNode name: 199+150, acc: 76.67, f1:86.79, samples: 60, 199+094=46/60=0.77, 150+019=0/0=nan\n",
      "\tNode name: 199+094, acc: 100.0, f1:100.0, samples: 60, 199+028=60/60=1.0, cub_094_White_breasted_Nuthatch=0/0=nan\n",
      "\tNode name: 199+028, acc: 100.0, f1:100.0, samples: 60, 199+198=60/60=1.0, cub_028_Brown_Creeper=0/0=nan\n",
      "\tNode name: 199+198, acc: 0.0, f1:0.0, samples: 60, 199+194=0/0=nan, cub_198_Rock_Wren=0/60=0.0\n",
      "cub_198_Rock_Wren 0.53 ----------\n",
      "\n",
      "\n",
      "classes_to_keep ['cub_014_Indigo_Bunting']\n",
      "leave_out_loader Unique Labels: {13}\n",
      "leave_out_loader total_samples: 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Epoch0: 100% 1/1 [00:00<00:00,  1.84it/s, L:0.025,LC:0.409, L_OVSP:-0.004, L_MASKL1:0.001, LA_PF:0.008, LT:-5.000, L_ORTH:0.004, LT_DESC:-5.000, L_OOD_ENT:-5.000, losses_used:MASK_PRUNING+MIN_CONT+AL_PF+KO+CL]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tFine accuracy: 0.9667\n",
      "\tNode name: root, acc: 100.0, f1:100.0, samples: 60, 129+024+067=60/60=1.0, 089+046=0/0=nan\n",
      "\tNode name: 129+024+067, acc: 100.0, f1:100.0, samples: 60, 129+065=60/60=1.0, 024+051=0/0=nan, 067+070=0/0=nan\n",
      "\tNode name: 129+065, acc: 100.0, f1:100.0, samples: 60, 129+192=60/60=1.0, 065+006=0/0=nan\n",
      "\tNode name: 129+192, acc: 100.0, f1:100.0, samples: 60, 129+043=60/60=1.0, 192+081=0/0=nan\n",
      "\tNode name: 129+043, acc: 100.0, f1:100.0, samples: 60, 129+018=60/60=1.0, 043+078=0/0=nan\n",
      "\tNode name: 129+018, acc: 100.0, f1:100.0, samples: 60, 129+107=60/60=1.0, cub_018_Spotted_Catbird=0/0=nan\n",
      "\tNode name: 129+107, acc: 100.0, f1:100.0, samples: 60, 129+136=60/60=1.0, 107+151=0/0=nan\n",
      "\tNode name: 129+136, acc: 100.0, f1:100.0, samples: 60, 129+199=60/60=1.0, 136+085=0/0=nan\n",
      "\tNode name: 129+199, acc: 100.0, f1:100.0, samples: 60, 129+118=60/60=1.0, 199+186=0/0=nan\n",
      "\tNode name: 129+118, acc: 100.0, f1:100.0, samples: 60, 129+104=60/60=1.0, cub_118_House_Sparrow=0/0=nan\n",
      "\tNode name: 129+104, acc: 100.0, f1:100.0, samples: 60, 129+035=60/60=1.0, cub_104_American_Pipit=0/0=nan\n",
      "\tNode name: 129+035, acc: 100.0, f1:100.0, samples: 60, 129+054=60/60=1.0, 035+055=0/0=nan\n",
      "\tNode name: 129+054, acc: 90.0, f1:94.74, samples: 60, 129+175=0/0=nan, 054+140=54/60=0.9\n",
      "\tNode name: 054+140, acc: 100.0, f1:100.0, samples: 60, 054+057=60/60=1.0, 140+017=0/0=nan\n",
      "\tNode name: 054+057, acc: 100.0, f1:100.0, samples: 60, 054+014=60/60=1.0, cub_057_Rose_breasted_Grosbeak=0/0=nan\n",
      "\tNode name: 054+014, acc: 0.0, f1:0.0, samples: 60, 054+016=0/0=nan, cub_014_Indigo_Bunting=0/60=0.0\n",
      "cub_014_Indigo_Bunting 0.97 ----------\n",
      "\n",
      "\n",
      "classes_to_keep ['cub_185_Bohemian_Waxwing']\n",
      "leave_out_loader Unique Labels: {174}\n",
      "leave_out_loader total_samples: 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Epoch0: 100% 1/1 [00:00<00:00,  1.92it/s, L:0.055,LC:0.665, L_OVSP:-0.004, L_MASKL1:0.001, LA_PF:0.010, LT:-5.000, L_ORTH:0.005, LT_DESC:-5.000, L_OOD_ENT:-5.000, losses_used:MASK_PRUNING+MIN_CONT+AL_PF+KO+CL]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tFine accuracy: 0.7\n",
      "\tNode name: root, acc: 90.0, f1:94.74, samples: 60, 129+024+067=54/60=0.9, 089+046=0/0=nan\n",
      "\tNode name: 129+024+067, acc: 90.0, f1:94.74, samples: 60, 129+065=54/60=0.9, 024+051=0/0=nan, 067+070=0/0=nan\n",
      "\tNode name: 129+065, acc: 100.0, f1:100.0, samples: 60, 129+192=60/60=1.0, 065+006=0/0=nan\n",
      "\tNode name: 129+192, acc: 100.0, f1:100.0, samples: 60, 129+043=60/60=1.0, 192+081=0/0=nan\n",
      "\tNode name: 129+043, acc: 93.33, f1:96.55, samples: 60, 129+018=56/60=0.93, 043+078=0/0=nan\n",
      "\tNode name: 129+018, acc: 93.33, f1:96.55, samples: 60, 129+107=56/60=0.93, cub_018_Spotted_Catbird=0/0=nan\n",
      "\tNode name: 129+107, acc: 93.33, f1:96.55, samples: 60, 129+136=56/60=0.93, 107+151=0/0=nan\n",
      "\tNode name: 129+136, acc: 80.0, f1:88.89, samples: 60, 129+199=48/60=0.8, 136+085=0/0=nan\n",
      "\tNode name: 129+199, acc: 90.0, f1:94.74, samples: 60, 129+118=0/0=nan, 199+186=54/60=0.9\n",
      "\tNode name: 199+186, acc: 96.67, f1:98.31, samples: 60, 199+150=0/0=nan, 186+185=58/60=0.97\n",
      "\tNode name: 186+185, acc: 0.0, f1:0.0, samples: 60, cub_186_Cedar_Waxwing=0/0=nan, cub_185_Bohemian_Waxwing=0/60=0.0\n",
      "cub_185_Bohemian_Waxwing 0.7 ----------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Sampler, SubsetRandomSampler\n",
    "\n",
    "def create_filtered_dataloader(dataloader, new_sampler, batch_size):\n",
    "    if type(dataloader.dataset) == ImageFolder:\n",
    "        dataset = dataloader.dataset\n",
    "    else:\n",
    "        dataset = dataloader.dataset.dataset.dataset\n",
    "    new_dataloader = DataLoader(\n",
    "        dataset=dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        sampler=new_sampler,\n",
    "        num_workers=dataloader.num_workers,\n",
    "        pin_memory=dataloader.pin_memory,\n",
    "        drop_last=dataloader.drop_last,\n",
    "        timeout=dataloader.timeout,\n",
    "        worker_init_fn=dataloader.worker_init_fn,\n",
    "        multiprocessing_context=dataloader.multiprocessing_context,\n",
    "        generator=dataloader.generator,\n",
    "        prefetch_factor=dataloader.prefetch_factor,\n",
    "        persistent_workers=dataloader.persistent_workers\n",
    "    )\n",
    "    return new_dataloader\n",
    "\n",
    "leave_out_loader = testloader\n",
    "\n",
    "for left_out_class in leave_out_classes:\n",
    "\n",
    "    classes_to_keep = [left_out_class]\n",
    "    \n",
    "    print('classes_to_keep', classes_to_keep)\n",
    "    idx_of_classes_to_keep = set()\n",
    "    name2label = leave_out_loader.dataset.class_to_idx # param\n",
    "    label2name = {label:name for name, label in name2label.items()}\n",
    "    for label in label2name:\n",
    "        # NOTE: Keeping the left out classes here\n",
    "        if label2name[label] in classes_to_keep:\n",
    "            idx_of_classes_to_keep.add(label)\n",
    "    \n",
    "    target_indices = []\n",
    "    for i in range(len(leave_out_loader.dataset)):\n",
    "        *_, label = leave_out_loader.dataset[i]\n",
    "        if label in idx_of_classes_to_keep:\n",
    "            target_indices.append(i)\n",
    "    sampler = SubsetRandomSampler(target_indices)\n",
    "    to_shuffle = False\n",
    "        \n",
    "    leave_out_loader = create_filtered_dataloader(leave_out_loader, sampler, batch_size=256) # dataloader.batch_size\n",
    "    unique_labels = set()\n",
    "    total_samples = 0\n",
    "    for xs, ys in leave_out_loader:\n",
    "        unique_labels.update(ys.tolist())\n",
    "        total_samples += xs.shape[0]\n",
    "    print(\"leave_out_loader Unique Labels:\", unique_labels)\n",
    "    print(\"leave_out_loader total_samples:\", total_samples)\n",
    "    \n",
    "    name2label = leave_out_loader.dataset.class_to_idx\n",
    "    label2name = {label:name for name, label in name2label.items()}\n",
    "    \n",
    "    # print('Leave out classes', args.leave_out_classes)\n",
    "\n",
    "    # testloader\n",
    "\n",
    "    test_info, log_dict = test_pipnet(net, leave_out_loader, optimizer_net, optimizer_classifier, \\\n",
    "                                        scheduler_net, scheduler_classifier, criterion, 0, \\\n",
    "                                            args.epochs, device, pretrain=False, finetune=False, \\\n",
    "                                            test_loader_OOD=testloader_OOD, kernel_orth=args.kernel_orth == 'y', \\\n",
    "                                                tanh_desc=args.tanh_desc == 'y', align=args.align == 'y', uni=args.uni == 'y', align_pf=args.align_pf == 'y',\\\n",
    "                                                minmaximize=args.minmaximize == 'y', wandb_run=wandb_run, pretrain_epochs=args.epochs_pretrain, log=log, \\\n",
    "                                              args=args, apply_overspecificity_mask=False, leave_out_classes=classes_to_keep, path_prob_softmax_tau=1)\n",
    "    print(left_out_class, round(test_info['fine_accuracy'], 2), '-'*10)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de034c67-9ede-412b-be53-789559a47892",
   "metadata": {},
   "source": [
    "## Leave out with mask pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a6c9c7f4-6a58-408f-88f4-410a0bd10f1e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Epoch0: 100% 2/2 [00:03<00:00,  1.62s/it, L:1.455,LC:1.571, L_OVSP:-0.006, L_MASKL1:0.002, LA_PF:0.019, LT:-5.000, L_ORTH:0.002, LT_DESC:-5.000, L_OOD_ENT:0.550, losses_used:MASK_PRUNING+MIN_CONT+AL_PF+KO+CL+OOD_ENT]\n",
      "/home/harishbabu/.conda/envs/hpnet4/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/harishbabu/.conda/envs/hpnet4/lib/python3.9/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tFine accuracy: 0.0\n",
      "\tNode name: root, acc: 0.0, f1:0.0, samples: 580, 129+024+067=0/580=0.0, 089+046=0/0=nan\n",
      "\tNode name: 129+024+067, acc: 24.48, f1:11.8, samples: 580, 129+065=0/418=0.0, 024+051=142/162=0.88, 067+070=0/0=nan\n",
      "\tNode name: 089+046, acc: inf, f1:inf, samples: 0, 089+090=0/0=nan, 046+087=0/0=nan\n",
      "\tNode name: 129+065, acc: 71.29, f1:59.34, samples: 418, 129+192=298/298=1.0, 065+006=0/120=0.0\n",
      "\tNode name: 024+051, acc: 37.04, f1:20.02, samples: 162, 024+031=0/102=0.0, 051+052=60/60=1.0\n",
      "\tNode name: 067+070, acc: inf, f1:inf, samples: 0, 067+068=0/0=nan, cub_070_Green_Violetear=0/0=nan\n",
      "\tNode name: 089+090, acc: inf, f1:inf, samples: 0, cub_089_Hooded_Merganser=0/0=nan, cub_090_Red_breasted_Merganser=0/0=nan\n",
      "\tNode name: 046+087, acc: inf, f1:inf, samples: 0, cub_046_Gadwall=0/0=nan, cub_087_Mallard=0/0=nan\n",
      "\tNode name: 129+192, acc: 20.13, f1:6.75, samples: 298, 129+043=0/238=0.0, 192+081=60/60=1.0\n",
      "\tNode name: 065+006, acc: 91.67, f1:95.65, samples: 120, 065+144=110/120=0.92, 006+071=0/0=nan\n",
      "\tNode name: 024+031, acc: 96.08, f1:96.06, samples: 102, 024+086=56/56=1.0, 031+004=42/46=0.91\n",
      "\tNode name: 051+052, acc: 100.0, f1:100.0, samples: 60, 051+053=60/60=1.0, cub_052_Pied_billed_Grebe=0/0=nan\n",
      "\tNode name: 067+068, acc: inf, f1:inf, samples: 0, 067+069=0/0=nan, cub_068_Ruby_throated_Hummingbird=0/0=nan\n",
      "\tNode name: 129+043, acc: 0.0, f1:0.0, samples: 238, 129+018=0/238=0.0, 043+078=0/0=nan\n",
      "\tNode name: 192+081, acc: 53.33, f1:69.57, samples: 60, 192+036=32/60=0.53, 081+083=0/0=nan\n",
      "\tNode name: 065+144, acc: 100.0, f1:100.0, samples: 120, 065+084=60/60=1.0, 144+147=60/60=1.0\n",
      "\tNode name: 006+071, acc: inf, f1:inf, samples: 0, 006+058=0/0=nan, 071+072=0/0=nan\n",
      "\tNode name: 024+086, acc: 89.29, f1:94.34, samples: 56, 024+001=50/56=0.89, cub_086_Pacific_Loon=0/0=nan\n",
      "\tNode name: 031+004, acc: 95.65, f1:97.78, samples: 46, 031+032=44/46=0.96, cub_004_Groove_billed_Ani=0/0=nan\n",
      "\tNode name: 051+053, acc: 80.0, f1:88.89, samples: 60, 051+050=48/60=0.8, cub_053_Western_Grebe=0/0=nan\n",
      "\tNode name: 067+069, acc: inf, f1:inf, samples: 0, cub_067_Anna_Hummingbird=0/0=nan, cub_069_Rufous_Hummingbird=0/0=nan\n",
      "\tNode name: 129+018, acc: 0.0, f1:0.0, samples: 238, 129+107=0/238=0.0, cub_018_Spotted_Catbird=0/0=nan\n",
      "\tNode name: 043+078, acc: inf, f1:inf, samples: 0, 043+042=0/0=nan, 078+038=0/0=nan\n",
      "\tNode name: 192+036, acc: 56.67, f1:72.34, samples: 60, 192+191=34/60=0.57, 036+188=0/0=nan\n",
      "\tNode name: 081+083, acc: inf, f1:inf, samples: 0, 081+082=0/0=nan, cub_083_White_breasted_Kingfisher=0/0=nan\n",
      "\tNode name: 065+084, acc: 13.33, f1:23.53, samples: 60, 065+061=0/0=nan, 084+063=8/60=0.13\n",
      "\tNode name: 144+147, acc: 0.0, f1:0.0, samples: 60, 144+143=0/0=nan, cub_147_Least_Tern=0/60=0.0\n",
      "\tNode name: 006+058, acc: inf, f1:inf, samples: 0, 006+008=0/0=nan, cub_058_Pigeon_Guillemot=0/0=nan\n",
      "\tNode name: 071+072, acc: inf, f1:inf, samples: 0, cub_071_Long_tailed_Jaeger=0/0=nan, cub_072_Pomarine_Jaeger=0/0=nan\n",
      "\tNode name: 024+001, acc: 92.86, f1:96.3, samples: 56, 024+100=0/0=nan, 001+045=52/56=0.93\n",
      "\tNode name: 031+032, acc: 0.0, f1:0.0, samples: 46, 031+033=0/0=nan, cub_032_Mangrove_Cuckoo=0/46=0.0\n",
      "\tNode name: 051+050, acc: 0.0, f1:0.0, samples: 60, cub_051_Horned_Grebe=0/60=0.0, cub_050_Eared_Grebe=0/0=nan\n",
      "\tNode name: 129+107, acc: 25.21, f1:10.15, samples: 238, 129+136=0/178=0.0, 107+151=60/60=1.0\n",
      "\tNode name: 043+042, acc: inf, f1:inf, samples: 0, 043+040=0/0=nan, cub_042_Vermilion_Flycatcher=0/0=nan\n",
      "\tNode name: 078+038, acc: inf, f1:inf, samples: 0, 078+041=0/0=nan, cub_038_Great_Crested_Flycatcher=0/0=nan\n",
      "\tNode name: 192+191, acc: 96.67, f1:98.31, samples: 60, 192+187=0/0=nan, 191+189=58/60=0.97\n",
      "\tNode name: 036+188, acc: inf, f1:inf, samples: 0, cub_036_Northern_Flicker=0/0=nan, cub_188_Pileated_Woodpecker=0/0=nan\n",
      "\tNode name: 081+082, acc: inf, f1:inf, samples: 0, 081+080=0/0=nan, 082+079=0/0=nan\n",
      "\tNode name: 065+061, acc: inf, f1:inf, samples: 0, 065+066=0/0=nan, 061+064=0/0=nan\n",
      "\tNode name: 084+063, acc: 0.0, f1:0.0, samples: 60, cub_084_Red_legged_Kittiwake=0/0=nan, cub_063_Ivory_Gull=0/60=0.0\n",
      "\tNode name: 144+143, acc: inf, f1:inf, samples: 0, 144+142=0/0=nan, cub_143_Caspian_Tern=0/0=nan\n",
      "\tNode name: 006+008, acc: inf, f1:inf, samples: 0, 006+005=0/0=nan, 008+106=0/0=nan\n",
      "\tNode name: 024+100, acc: inf, f1:inf, samples: 0, 024+023=0/0=nan, 100+101=0/0=nan\n",
      "\tNode name: 001+045, acc: 89.29, f1:94.34, samples: 56, 001+003=50/56=0.89, cub_045_Northern_Fulmar=0/0=nan\n",
      "\tNode name: 031+033, acc: inf, f1:inf, samples: 0, cub_031_Black_billed_Cuckoo=0/0=nan, cub_033_Yellow_billed_Cuckoo=0/0=nan\n",
      "\tNode name: 129+136, acc: 0.0, f1:0.0, samples: 178, 129+199=0/178=0.0, 136+085=0/0=nan\n",
      "\tNode name: 107+151, acc: 100.0, f1:100.0, samples: 60, 107+111=60/60=1.0, 151+153=0/0=nan\n",
      "\tNode name: 043+040, acc: inf, f1:inf, samples: 0, 043+037=0/0=nan, 040+102=0/0=nan\n",
      "\tNode name: 078+041, acc: inf, f1:inf, samples: 0, 078+077=0/0=nan, cub_041_Scissor_tailed_Flycatcher=0/0=nan\n",
      "\tNode name: 192+187, acc: inf, f1:inf, samples: 0, 192+190=0/0=nan, cub_187_American_Three_toed_Woodpecker=0/0=nan\n",
      "\tNode name: 191+189, acc: 0.0, f1:0.0, samples: 60, cub_191_Red_headed_Woodpecker=0/60=0.0, cub_189_Red_bellied_Woodpecker=0/0=nan\n",
      "\tNode name: 081+080, acc: inf, f1:inf, samples: 0, cub_081_Pied_Kingfisher=0/0=nan, cub_080_Green_Kingfisher=0/0=nan\n",
      "\tNode name: 082+079, acc: inf, f1:inf, samples: 0, cub_082_Ringed_Kingfisher=0/0=nan, cub_079_Belted_Kingfisher=0/0=nan\n",
      "\tNode name: 065+066, acc: inf, f1:inf, samples: 0, 065+062=0/0=nan, cub_066_Western_Gull=0/0=nan\n",
      "\tNode name: 061+064, acc: inf, f1:inf, samples: 0, cub_061_Heermann_Gull=0/0=nan, cub_064_Ring_billed_Gull=0/0=nan\n",
      "\tNode name: 144+142, acc: inf, f1:inf, samples: 0, 144+145=0/0=nan, cub_142_Black_Tern=0/0=nan\n",
      "\tNode name: 006+005, acc: inf, f1:inf, samples: 0, 006+007=0/0=nan, cub_005_Crested_Auklet=0/0=nan\n",
      "\tNode name: 008+106, acc: inf, f1:inf, samples: 0, cub_008_Rhinoceros_Auklet=0/0=nan, cub_106_Horned_Puffin=0/0=nan\n",
      "\tNode name: 024+023, acc: inf, f1:inf, samples: 0, 024+025=0/0=nan, cub_023_Brandt_Cormorant=0/0=nan\n",
      "\tNode name: 100+101, acc: inf, f1:inf, samples: 0, cub_100_Brown_Pelican=0/0=nan, cub_101_White_Pelican=0/0=nan\n",
      "\tNode name: 001+003, acc: 0.0, f1:0.0, samples: 56, 001+002=0/0=nan, cub_003_Sooty_Albatross=0/56=0.0\n",
      "\tNode name: 129+199, acc: 66.29, f1:52.85, samples: 178, 129+118=0/60=0.0, 199+186=118/118=1.0\n",
      "\tNode name: 136+085, acc: inf, f1:inf, samples: 0, 136+138=0/0=nan, cub_085_Horned_Lark=0/0=nan\n",
      "\tNode name: 107+111, acc: 100.0, f1:100.0, samples: 60, 107+073=60/60=1.0, 111+112=0/0=nan\n",
      "\tNode name: 151+153, acc: inf, f1:inf, samples: 0, 151+157=0/0=nan, 153+154=0/0=nan\n",
      "\tNode name: 043+037, acc: inf, f1:inf, samples: 0, 043+039=0/0=nan, cub_037_Acadian_Flycatcher=0/0=nan\n",
      "\tNode name: 040+102, acc: inf, f1:inf, samples: 0, cub_040_Olive_sided_Flycatcher=0/0=nan, cub_102_Western_Wood_Pewee=0/0=nan\n",
      "\tNode name: 078+077, acc: inf, f1:inf, samples: 0, cub_078_Gray_Kingbird=0/0=nan, cub_077_Tropical_Kingbird=0/0=nan\n",
      "\tNode name: 192+190, acc: inf, f1:inf, samples: 0, cub_192_Downy_Woodpecker=0/0=nan, cub_190_Red_cockaded_Woodpecker=0/0=nan\n",
      "\tNode name: 065+062, acc: inf, f1:inf, samples: 0, 065+059=0/0=nan, cub_062_Herring_Gull=0/0=nan\n",
      "\tNode name: 144+145, acc: inf, f1:inf, samples: 0, 144+146=0/0=nan, cub_145_Elegant_Tern=0/0=nan\n",
      "\tNode name: 006+007, acc: inf, f1:inf, samples: 0, cub_006_Least_Auklet=0/0=nan, cub_007_Parakeet_Auklet=0/0=nan\n",
      "\tNode name: 024+025, acc: inf, f1:inf, samples: 0, cub_024_Red_faced_Cormorant=0/0=nan, cub_025_Pelagic_Cormorant=0/0=nan\n",
      "\tNode name: 001+002, acc: inf, f1:inf, samples: 0, cub_001_Black_footed_Albatross=0/0=nan, cub_002_Laysan_Albatross=0/0=nan\n",
      "\tNode name: 129+118, acc: 0.0, f1:0.0, samples: 60, 129+104=0/60=0.0, cub_118_House_Sparrow=0/0=nan\n",
      "\tNode name: 199+186, acc: 91.53, f1:95.58, samples: 118, 199+150=108/118=0.92, 186+185=0/0=nan\n",
      "\tNode name: 136+138, acc: inf, f1:inf, samples: 0, 136+137=0/0=nan, cub_138_Tree_Swallow=0/0=nan\n",
      "\tNode name: 107+073, acc: 100.0, f1:100.0, samples: 60, 107+093=60/60=1.0, 073+074=0/0=nan\n",
      "\tNode name: 111+112, acc: inf, f1:inf, samples: 0, cub_111_Loggerhead_Shrike=0/0=nan, cub_112_Great_Grey_Shrike=0/0=nan\n",
      "\tNode name: 151+157, acc: inf, f1:inf, samples: 0, 151+156=0/0=nan, 157+152=0/0=nan\n",
      "\tNode name: 153+154, acc: inf, f1:inf, samples: 0, 153+155=0/0=nan, cub_154_Red_eyed_Vireo=0/0=nan\n",
      "\tNode name: 043+039, acc: inf, f1:inf, samples: 0, cub_043_Yellow_bellied_Flycatcher=0/0=nan, cub_039_Least_Flycatcher=0/0=nan\n",
      "\tNode name: 065+059, acc: inf, f1:inf, samples: 0, 065+060=0/0=nan, cub_059_California_Gull=0/0=nan\n",
      "\tNode name: 144+146, acc: inf, f1:inf, samples: 0, 144+141=0/0=nan, cub_146_Forsters_Tern=0/0=nan\n",
      "\tNode name: 129+104, acc: 0.0, f1:0.0, samples: 60, 129+035=0/60=0.0, cub_104_American_Pipit=0/0=nan\n",
      "\tNode name: 199+150, acc: 83.05, f1:83.04, samples: 118, 199+094=48/60=0.8, 150+019=50/58=0.86\n",
      "\tNode name: 186+185, acc: inf, f1:inf, samples: 0, cub_186_Cedar_Waxwing=0/0=nan, cub_185_Bohemian_Waxwing=0/0=nan\n",
      "\tNode name: 136+137, acc: inf, f1:inf, samples: 0, cub_136_Barn_Swallow=0/0=nan, cub_137_Cliff_Swallow=0/0=nan\n",
      "\tNode name: 107+093, acc: 100.0, f1:100.0, samples: 60, 107+030=60/60=1.0, cub_093_Clark_Nutcracker=0/0=nan\n",
      "\tNode name: 073+074, acc: inf, f1:inf, samples: 0, cub_073_Blue_Jay=0/0=nan, cub_074_Florida_Jay=0/0=nan\n",
      "\tNode name: 151+156, acc: inf, f1:inf, samples: 0, cub_151_Black_capped_Vireo=0/0=nan, cub_156_White_eyed_Vireo=0/0=nan\n",
      "\tNode name: 157+152, acc: inf, f1:inf, samples: 0, cub_157_Yellow_throated_Vireo=0/0=nan, cub_152_Blue_headed_Vireo=0/0=nan\n",
      "\tNode name: 153+155, acc: inf, f1:inf, samples: 0, cub_153_Philadelphia_Vireo=0/0=nan, cub_155_Warbling_Vireo=0/0=nan\n",
      "\tNode name: 065+060, acc: inf, f1:inf, samples: 0, cub_065_Slaty_backed_Gull=0/0=nan, cub_060_Glaucous_winged_Gull=0/0=nan\n",
      "\tNode name: 144+141, acc: inf, f1:inf, samples: 0, cub_144_Common_Tern=0/0=nan, cub_141_Artic_Tern=0/0=nan\n",
      "\tNode name: 129+035, acc: 0.0, f1:0.0, samples: 60, 129+054=0/60=0.0, 035+055=0/0=nan\n",
      "\tNode name: 199+094, acc: 96.67, f1:98.31, samples: 60, 199+028=58/60=0.97, cub_094_White_breasted_Nuthatch=0/0=nan\n",
      "\tNode name: 150+019, acc: 100.0, f1:100.0, samples: 58, 150+149=58/58=1.0, cub_019_Gray_Catbird=0/0=nan\n",
      "\tNode name: 107+030, acc: 0.0, f1:0.0, samples: 60, 107+029=0/0=nan, cub_030_Fish_Crow=0/60=0.0\n",
      "\tNode name: 129+054, acc: 100.0, f1:100.0, samples: 60, 129+175=0/0=nan, 054+140=60/60=1.0\n",
      "\tNode name: 035+055, acc: inf, f1:inf, samples: 0, 035+048=0/0=nan, cub_055_Evening_Grosbeak=0/0=nan\n",
      "\tNode name: 199+028, acc: 93.33, f1:96.55, samples: 60, 199+198=56/60=0.93, cub_028_Brown_Creeper=0/0=nan\n",
      "\tNode name: 150+149, acc: 0.0, f1:0.0, samples: 58, 150+091=0/0=nan, cub_149_Brown_Thrasher=0/58=0.0\n",
      "\tNode name: 107+029, acc: inf, f1:inf, samples: 0, 107+108=0/0=nan, cub_029_American_Crow=0/0=nan\n",
      "\tNode name: 129+175, acc: inf, f1:inf, samples: 0, 129+011=0/0=nan, 175+020=0/0=nan\n",
      "\tNode name: 054+140, acc: 100.0, f1:100.0, samples: 60, 054+057=0/0=nan, 140+017=60/60=1.0\n",
      "\tNode name: 035+048, acc: inf, f1:inf, samples: 0, 035+056=0/0=nan, 048+047=0/0=nan\n",
      "\tNode name: 199+198, acc: 3.33, f1:6.45, samples: 60, 199+194=0/0=nan, cub_198_Rock_Wren=2/60=0.03\n",
      "\tNode name: 150+091, acc: inf, f1:inf, samples: 0, cub_150_Sage_Thrasher=0/0=nan, cub_091_Mockingbird=0/0=nan\n",
      "\tNode name: 107+108, acc: inf, f1:inf, samples: 0, cub_107_Common_Raven=0/0=nan, cub_108_White_necked_Raven=0/0=nan\n",
      "\tNode name: 129+011, acc: inf, f1:inf, samples: 0, 129+121=0/0=nan, 011+013=0/0=nan\n",
      "\tNode name: 175+020, acc: inf, f1:inf, samples: 0, 175+099=0/0=nan, cub_020_Yellow_breasted_Chat=0/0=nan\n",
      "\tNode name: 054+057, acc: inf, f1:inf, samples: 0, 054+014=0/0=nan, cub_057_Rose_breasted_Grosbeak=0/0=nan\n",
      "\tNode name: 140+017, acc: 83.33, f1:90.91, samples: 60, 140+139=50/60=0.83, cub_017_Cardinal=0/0=nan\n",
      "\tNode name: 035+056, acc: inf, f1:inf, samples: 0, 035+034=0/0=nan, cub_056_Pine_Grosbeak=0/0=nan\n",
      "\tNode name: 048+047, acc: inf, f1:inf, samples: 0, cub_048_European_Goldfinch=0/0=nan, cub_047_American_Goldfinch=0/0=nan\n",
      "\tNode name: 199+194, acc: inf, f1:inf, samples: 0, 199+193=0/0=nan, cub_194_Cactus_Wren=0/0=nan\n",
      "\tNode name: 129+121, acc: inf, f1:inf, samples: 0, 129+117=0/0=nan, cub_121_Grasshopper_Sparrow=0/0=nan\n",
      "\tNode name: 011+013, acc: inf, f1:inf, samples: 0, 011+095=0/0=nan, 013+088=0/0=nan\n",
      "\tNode name: 175+099, acc: inf, f1:inf, samples: 0, 175+181=0/0=nan, cub_099_Ovenbird=0/0=nan\n",
      "\tNode name: 054+014, acc: inf, f1:inf, samples: 0, 054+016=0/0=nan, cub_014_Indigo_Bunting=0/0=nan\n",
      "\tNode name: 140+139, acc: 0.0, f1:0.0, samples: 60, cub_140_Summer_Tanager=0/0=nan, cub_139_Scarlet_Tanager=0/60=0.0\n",
      "\tNode name: 035+034, acc: inf, f1:inf, samples: 0, cub_035_Purple_Finch=0/0=nan, cub_034_Gray_crowned_Rosy_Finch=0/0=nan\n",
      "\tNode name: 199+193, acc: inf, f1:inf, samples: 0, 199+197=0/0=nan, 193+195=0/0=nan\n",
      "\tNode name: 129+117, acc: inf, f1:inf, samples: 0, 129+133=0/0=nan, 117+114=0/0=nan\n",
      "\tNode name: 011+095, acc: inf, f1:inf, samples: 0, 011+026=0/0=nan, 095+096=0/0=nan\n",
      "\tNode name: 013+088, acc: inf, f1:inf, samples: 0, 013+012=0/0=nan, cub_088_Western_Meadowlark=0/0=nan\n",
      "\tNode name: 175+181, acc: inf, f1:inf, samples: 0, 175+168+173+183=0/0=nan, cub_181_Worm_eating_Warbler=0/0=nan\n",
      "\tNode name: 054+016, acc: inf, f1:inf, samples: 0, 054+015=0/0=nan, cub_016_Painted_Bunting=0/0=nan\n",
      "\tNode name: 199+197, acc: inf, f1:inf, samples: 0, 199+196=0/0=nan, cub_197_Marsh_Wren=0/0=nan\n",
      "\tNode name: 193+195, acc: inf, f1:inf, samples: 0, cub_193_Bewick_Wren=0/0=nan, cub_195_Carolina_Wren=0/0=nan\n",
      "\tNode name: 129+133, acc: inf, f1:inf, samples: 0, 129+021=0/0=nan, 133+130=0/0=nan\n",
      "\tNode name: 117+114, acc: inf, f1:inf, samples: 0, 117+115=0/0=nan, cub_114_Black_throated_Sparrow=0/0=nan\n",
      "\tNode name: 011+026, acc: inf, f1:inf, samples: 0, 011+049=0/0=nan, 026+010=0/0=nan\n",
      "\tNode name: 095+096, acc: inf, f1:inf, samples: 0, 095+098=0/0=nan, 096+097=0/0=nan\n",
      "\tNode name: 013+012, acc: inf, f1:inf, samples: 0, cub_013_Bobolink=0/0=nan, cub_012_Yellow_headed_Blackbird=0/0=nan\n",
      "\tNode name: 175+168+173+183, acc: inf, f1:inf, samples: 0, 175+162=0/0=nan, 168+177=0/0=nan, 173+161=0/0=nan, 183+159=0/0=nan\n",
      "\tNode name: 054+015, acc: inf, f1:inf, samples: 0, cub_054_Blue_Grosbeak=0/0=nan, cub_015_Lazuli_Bunting=0/0=nan\n",
      "\tNode name: 199+196, acc: inf, f1:inf, samples: 0, cub_199_Winter_Wren=0/0=nan, cub_196_House_Wren=0/0=nan\n",
      "\tNode name: 129+021, acc: inf, f1:inf, samples: 0, 129+128=0/0=nan, 021+148=0/0=nan\n",
      "\tNode name: 133+130, acc: inf, f1:inf, samples: 0, 133+076=0/0=nan, 130+120=0/0=nan\n",
      "\tNode name: 117+115, acc: inf, f1:inf, samples: 0, 117+116=0/0=nan, 115+119=0/0=nan\n",
      "\tNode name: 011+049, acc: inf, f1:inf, samples: 0, 011+009=0/0=nan, cub_049_Boat_tailed_Grackle=0/0=nan\n",
      "\tNode name: 026+010, acc: inf, f1:inf, samples: 0, 026+027=0/0=nan, cub_010_Red_winged_Blackbird=0/0=nan\n",
      "\tNode name: 095+098, acc: inf, f1:inf, samples: 0, cub_095_Baltimore_Oriole=0/0=nan, cub_098_Scott_Oriole=0/0=nan\n",
      "\tNode name: 096+097, acc: inf, f1:inf, samples: 0, cub_096_Hooded_Oriole=0/0=nan, cub_097_Orchard_Oriole=0/0=nan\n",
      "\tNode name: 175+162, acc: inf, f1:inf, samples: 0, 175+167=0/0=nan, 162+180=0/0=nan\n",
      "\tNode name: 168+177, acc: inf, f1:inf, samples: 0, 168+200=0/0=nan, 177+178=0/0=nan\n",
      "\tNode name: 173+161, acc: inf, f1:inf, samples: 0, 173+179=0/0=nan, 161+166=0/0=nan\n",
      "\tNode name: 183+159, acc: inf, f1:inf, samples: 0, 183+184=0/0=nan, cub_159_Black_and_white_Warbler=0/0=nan\n",
      "\tNode name: 129+128, acc: inf, f1:inf, samples: 0, 129+127=0/0=nan, 128+131=0/0=nan\n",
      "\tNode name: 021+148, acc: inf, f1:inf, samples: 0, cub_021_Eastern_Towhee=0/0=nan, cub_148_Green_tailed_Towhee=0/0=nan\n",
      "\tNode name: 133+076, acc: inf, f1:inf, samples: 0, 133+132=0/0=nan, cub_076_Dark_eyed_Junco=0/0=nan\n",
      "\tNode name: 130+120, acc: inf, f1:inf, samples: 0, cub_130_Tree_Sparrow=0/0=nan, cub_120_Fox_Sparrow=0/0=nan\n",
      "\tNode name: 117+116, acc: inf, f1:inf, samples: 0, cub_117_Clay_colored_Sparrow=0/0=nan, cub_116_Chipping_Sparrow=0/0=nan\n",
      "\tNode name: 115+119, acc: inf, f1:inf, samples: 0, cub_115_Brewer_Sparrow=0/0=nan, cub_119_Field_Sparrow=0/0=nan\n",
      "\tNode name: 011+009, acc: inf, f1:inf, samples: 0, cub_011_Rusty_Blackbird=0/0=nan, cub_009_Brewer_Blackbird=0/0=nan\n",
      "\tNode name: 026+027, acc: inf, f1:inf, samples: 0, cub_026_Bronzed_Cowbird=0/0=nan, cub_027_Shiny_Cowbird=0/0=nan\n",
      "\tNode name: 175+167, acc: inf, f1:inf, samples: 0, 175+169=0/0=nan, cub_167_Hooded_Warbler=0/0=nan\n",
      "\tNode name: 162+180, acc: inf, f1:inf, samples: 0, cub_162_Canada_Warbler=0/0=nan, cub_180_Wilson_Warbler=0/0=nan\n",
      "\tNode name: 168+200, acc: inf, f1:inf, samples: 0, 168+170=0/0=nan, cub_200_Common_Yellowthroat=0/0=nan\n",
      "\tNode name: 177+178, acc: inf, f1:inf, samples: 0, cub_177_Prothonotary_Warbler=0/0=nan, cub_178_Swainson_Warbler=0/0=nan\n",
      "\tNode name: 173+179, acc: inf, f1:inf, samples: 0, 173+172=0/0=nan, cub_179_Tennessee_Warbler=0/0=nan\n",
      "\tNode name: 161+166, acc: inf, f1:inf, samples: 0, cub_161_Blue_winged_Warbler=0/0=nan, cub_166_Golden_winged_Warbler=0/0=nan\n",
      "\tNode name: 183+184, acc: inf, f1:inf, samples: 0, cub_183_Northern_Waterthrush=0/0=nan, cub_184_Louisiana_Waterthrush=0/0=nan\n",
      "\tNode name: 129+127, acc: inf, f1:inf, samples: 0, 129+123=0/0=nan, cub_127_Savannah_Sparrow=0/0=nan\n",
      "\tNode name: 128+131, acc: inf, f1:inf, samples: 0, 128+124=0/0=nan, cub_131_Vesper_Sparrow=0/0=nan\n",
      "\tNode name: 133+132, acc: inf, f1:inf, samples: 0, 133+122=0/0=nan, cub_132_White_crowned_Sparrow=0/0=nan\n",
      "\tNode name: 175+169, acc: inf, f1:inf, samples: 0, 175+165+182=0/0=nan, cub_169_Magnolia_Warbler=0/0=nan\n",
      "\tNode name: 168+170, acc: inf, f1:inf, samples: 0, cub_168_Kentucky_Warbler=0/0=nan, cub_170_Mourning_Warbler=0/0=nan\n",
      "\tNode name: 173+172, acc: inf, f1:inf, samples: 0, cub_173_Orange_crowned_Warbler=0/0=nan, cub_172_Nashville_Warbler=0/0=nan\n",
      "\tNode name: 129+123, acc: inf, f1:inf, samples: 0, 129+125=0/0=nan, 123+113=0/0=nan\n",
      "\tNode name: 128+124, acc: inf, f1:inf, samples: 0, 128+126=0/0=nan, cub_124_Le_Conte_Sparrow=0/0=nan\n",
      "\tNode name: 133+122, acc: inf, f1:inf, samples: 0, cub_133_White_throated_Sparrow=0/0=nan, cub_122_Harris_Sparrow=0/0=nan\n",
      "\tNode name: 175+165+182, acc: inf, f1:inf, samples: 0, 175+160=0/0=nan, 165+164+163=0/0=nan, cub_182_Yellow_Warbler=0/0=nan\n",
      "\tNode name: 129+125, acc: inf, f1:inf, samples: 0, cub_129_Song_Sparrow=0/0=nan, cub_125_Lincoln_Sparrow=0/0=nan\n",
      "\tNode name: 123+113, acc: inf, f1:inf, samples: 0, cub_123_Henslow_Sparrow=0/0=nan, cub_113_Baird_Sparrow=0/0=nan\n",
      "\tNode name: 128+126, acc: inf, f1:inf, samples: 0, cub_128_Seaside_Sparrow=0/0=nan, cub_126_Nelson_Sharp_tailed_Sparrow=0/0=nan\n",
      "\tNode name: 175+160, acc: inf, f1:inf, samples: 0, 175+176=0/0=nan, 160+109=0/0=nan\n",
      "\tNode name: 165+164+163, acc: inf, f1:inf, samples: 0, 165+158=0/0=nan, cub_164_Cerulean_Warbler=0/0=nan, cub_163_Cape_May_Warbler=0/0=nan\n",
      "\tNode name: 175+176, acc: inf, f1:inf, samples: 0, 175+174=0/0=nan, cub_176_Prairie_Warbler=0/0=nan\n",
      "\tNode name: 160+109, acc: inf, f1:inf, samples: 0, cub_160_Black_throated_Blue_Warbler=0/0=nan, cub_109_American_Redstart=0/0=nan\n",
      "\tNode name: 165+158, acc: inf, f1:inf, samples: 0, cub_165_Chestnut_sided_Warbler=0/0=nan, cub_158_Bay_breasted_Warbler=0/0=nan\n",
      "\tNode name: 175+174, acc: inf, f1:inf, samples: 0, cub_175_Pine_Warbler=0/0=nan, cub_174_Palm_Warbler=0/0=nan\n"
     ]
    }
   ],
   "source": [
    "# testloader\n",
    "\n",
    "test_info, log_dict = test_pipnet(net, leave_out_loader, optimizer_net, optimizer_classifier, \\\n",
    "                                    scheduler_net, scheduler_classifier, criterion, 0, \\\n",
    "                                        args.epochs, device, pretrain=False, finetune=False, \\\n",
    "                                        test_loader_OOD=testloader_OOD, kernel_orth=args.kernel_orth == 'y', \\\n",
    "                                            tanh_desc=args.tanh_desc == 'y', align=args.align == 'y', uni=args.uni == 'y', align_pf=args.align_pf == 'y',\\\n",
    "                                            minmaximize=args.minmaximize == 'y', wandb_run=wandb_run, pretrain_epochs=args.epochs_pretrain, log=log, \\\n",
    "                                          args=args, apply_overspecificity_mask=True, leave_out_classes=leave_out_classes, path_prob_softmax_tau=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "77dfced7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(net.module._root_proto_presence)\n",
    "# print(net.module._root_proto_presence.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1c939568-6ca9-45c9-a4d8-b444ffafd662",
   "metadata": {},
   "outputs": [],
   "source": [
    "# net.module._root_proto_presence[:, 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1f15b657-6768-4f92-95ac-1219edecec44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.cat([net.module._root_proto_presence[:, 1].unsqueeze(-1), net.module._root_proto_presence[:, 0].unsqueeze(-1)], dim=-1)#.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "024d55a8-209d-4325-af85-66afbe199ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with torch.no_grad():\n",
    "#     for node in root.nodes_with_children():\n",
    "#         net.module._root_proto_presence\n",
    "#         proto_presence = getattr(net.module, '_'+node.name+'_proto_presence')\n",
    "#         reversed_proto_presence = torch.cat([proto_presence[:, 1].unsqueeze(-1), proto_presence[:, 0].unsqueeze(-1)], dim=-1)\n",
    "#         setattr(net.module, '_'+node.name+'_proto_presence', \\\n",
    "#                 nn.Parameter(reversed_proto_presence))\n",
    "\n",
    "#     test_info, log_dict = test_pipnet(net, leave_out_loader, optimizer_net, optimizer_classifier, \\\n",
    "#                                     scheduler_net, scheduler_classifier, criterion, 0, \\\n",
    "#                                         args.epochs, device, pretrain=False, finetune=False, \\\n",
    "#                                         test_loader_OOD=testloader_OOD, kernel_orth=args.kernel_orth == 'y', \\\n",
    "#                                             tanh_desc=args.tanh_desc == 'y', align=args.align == 'y', uni=args.uni == 'y', align_pf=args.align_pf == 'y',\\\n",
    "#                                             minmaximize=args.minmaximize == 'y', wandb_run=wandb_run, pretrain_epochs=args.epochs_pretrain, log=log, \\\n",
    "#                                           args=args, apply_overspecificity_mask=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a43dc275-1062-4aa9-9628-e5a9ce35c1e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([False, True, True]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46aa7a0a-f573-4cca-932a-40340dcb3954",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
